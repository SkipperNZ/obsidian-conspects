
[[Big_data practicum made]]



# Лекция 1

Рассматривыемые темы в курсе:

![[Pasted image 20220403044905.png]]

Всего 3 подкурса:
![[Pasted image 20220403045225.png]]

![[Pasted image 20220403045251.png]]

![[Pasted image 20220403045348.png]]


Big data это 3v.

Объем(volume) - скорость(velocity) -разнообразие(variety)

Это маркетинговое определение
![[Pasted image 20220403161132.png]]

Многопроцессорные (>1) вычислительные системы - МВС

Это когда много процессоров, организованных в сеть, для производства вычислений. 

Компоненты МВС
* Сервера(узлы)

При поломке сервера МВС может предоставлять следующие гарантии (Node Failures)
1) не предоставлять гарантии стабильной работы всей системы в случае поломки хотя бы 1 сервера.  Это называется Fail-Stop
2) Система будет работать даже при поломке отдельных компонентов.  Это называется Fail-Recovery. Этого можно добиться за счет дублирования либо данных, либо вычислений. 
3) Byzantine - самый крутой уровень.  Устойчивость к византийским отказам узлов. (византийские - узлы. узлы которые были скомпроментированы, запущено вредоносное ПО). Решение - еще больший объем дублирования.   Собираем информацию и данные с разных дублированных серверов и устраиваем голосовалку. Тех что больше - правильные. Остальные вредоносные 


* Сеть(соединения) - так же есть 3 уровня гарантии при поломке сети. (Link Failures)
1)  Perfect Link - соединения, которые гарантируют доставку всех сообщений, их целостность, порядок доставки, и исключение сбоев. 
2) Fair-Loss Link (сети справедливой потери данных) - если мы предполагаем что сообщения могут теряться. Сервер считает что какие то сообщения могут быть утеряны (а значит и доставлены от одного сервера к другому в случайном порядке). Но гарантировано, что никаких "Левых" сообщений в сети не будет. Утеряные сообщения повторно отправляются.
3) Byzantie  -  Пакеты могут не просто теряться, а блокироваться в зависимости от их содержимого. Сообщения могут быть модифицированы и могут появляться из ниоткуда. Что бы стабилизироваться в этом случае, нужно делать много работы. и собирать кворум ответов с разных частей сети.
* Модель синхронности - установка одинакового времени. А синхронизация происходит через сеть, где возможны задержки. Синхронизация происходит через алгоритм cristian(вроде так услышал на записи) Ключевые проблемы такие:
1) Clock Skew - разница в абсолютном значении времени на разных компьютерах
2) Clock Drift - изменение скорости течения времени с целью синхронизации 

Если мы можем гарантировать что сообщения будут доставлены всегда за заданный промежуток времени и разница в Skew и Drift ограничены, то мы живём в синхронной модели мира. 
Если хотя бы одно из условий неверно, то модель мира асинхронна. 

В зависимости от набора гарантий, мы попадаем в ту или иную сферу computer science 

**Fail-stop + Perfect Link + Synchronus**
Эта сфера называется - параллельные вычисления.
Это что то вроде суперкомпьютера "Ломоносов-2"
При работе с ними почти наверняка познакомимся с системами OpenMP и MPI

**Fail-Recovery + Fair-Loss Link + Asynchronous**
Эта сфера называется - распределённые вычисления.
Частые фреймворки: Hadoop, HIVE, Spark

**Byzantie-Failture + Byzantie Link + Asynchronous**
Эта сфера называется - Грид вычисления. 


Рассмотрим несколько примеров. 
**Blockchain** -  Грид вычисления. 

Federated Machine Learning - машин лёрнинг в грид вычислениях
![[Pasted image 20220403170802.png]]

Например штука, которая предлагает дописать следующее слово


Итак, Big data - в большинстве случаев - распределённые вычисления, чуть реже - грид вычисления. 



### Распределенные файловые системы на примере GFS и HDFS

GFS - google file system
HDFS - hadoop distributed file system

Для того что бы решать огромные задачи можно либо купить топовое железо, либо что бы уменьшить стоимость оборудования  использовать gfs и map reduce
Закупается стандартное оборудование

![[Pasted image 20220403174952.png]]

Есть и обратная сторона медали увеличивается вероятность поломки одного из узлов 

**Как обеспечить гарантии хранения данных в рамках fail-recovery?**

За счет дублирования данных (реплекация)

**Как храним файлы размером 2 TB и 10 TB в кластере?**

разбить датасеты на чанки и расфасовать по кластерам

S - маленький датасет
B - большой 
нарезаем всё на кусочки по 125гб 

![[Pasted image 20220403180018.png]]

Помогает ли такая модель случайного расположения чанков по кластеру сэкономить ресурсы на восстановление реплик в случае выхода из строя одного из  серверов.
- Нет
Если расположили чанки не случайно, но загрузка была бы сбалансирована, то число потеряных чанков которые нужно восстановить одинаковы в обоих случаях

Какие бонусы от того что мы можем раскидать чанки одного файла равномерно по всему кластеру. 
- возможность параллельно обработать разные куски файла на разных машинах. 


**Принципы GFS**

* Поломки компонент - это норма (используем репликацию)
* Равномерная утилизация компонент кластера.
* семантика write-ones-read-many (в случае работы с большими данными мы обычно записываем данные один раз, а читаем много) то есть мы можем пожертвовать скоростью упаковки данных для кластера что бы все следующие пайплайны, которые будут эти данные использовать работали в разы быстрее. 

![[Pasted image 20220403181310.png]]

Перейдём к HDFS

![[Pasted image 20220403181606.png]]

Отличая:
* чанки называются блоками
* мастер называется namenode
* чанксервер называется datanode

HDFS - это просто опенсорс реализация GFS

###  Чтение и запись данных в HDFS
![[Pasted image 20220403182414.png]]

**Как определить "ближайшую" ноду в кластере?**

- считаем пинг по сети между узлами (можно накосячить так как нагрузка динамическая)

В реальности разработчики хадупа приняли решение что для определения слова "ближайший" стоит полагаться на статическую топологию кластеров. 
![[Pasted image 20220403183005.png]]

Если мы находимся на физической ноде кластера где доступен data node. то расстояние равно нулю. Тогда мы можем избежать открытия сетевого соединения, и читать данные напрямую с жесткого диска. 
Если же данных локально нет то надо погулять по сети. 
каждый шаг (от сервера до свича, от свича до другого сервера, от свича до другого свича на другой стойке итд) на схеме количество шагов обозначено **d** 


**Запись данных** 
![[Pasted image 20220403183538.png]]


**Как расположить реплики с учетом сетевой топологии кластера?**

1-ую реплику кладём "под себя" максимально близко к клиенту 0-2 шага

2-ую реплику максимально далеко в случае датасета в одной географической логации - расстояние 4. 

все остальные реплики распологаем случайным образом

Это всё в случае когда всё хорошо.

### W1L106. Работа со сбоями в HDFS - чанки, блоки и реплики

Введём несколько понятий:
* чанк - кусок данных которые клиент хочет записать в распределённую файловую систему
* блок - метаинформация по этому чанку, которая хранится на namenode
* реплика - физическая копия чанка на datanode
* generation step - блоки и реплики имеют свои идентификаторы, но поскольку запись данных в распределённые хранилища - это не атомарная операция то в дополнении к идентификатору и реплики и блоки имеют номер эпохи hdfs - это и есть generation step


![[Pasted image 20220403231054.png]]

![[Pasted image 20220403231833.png]]


**Что такое generation step?**
Эпоха - это период существования HDFS без сбоя. если какие то 2 сущности одного чанка(реплики или блок) имеют  разные номера эпох, то это означает, что в период работы hdfs был сбой. И нужно восстановить консистентность hdfs как минимум для этого чанка. 

Есть 4 процедуры восстановления: 
* **Replica Recovery** - процедура восстановления реплик.
* **Block Recovery** - восстановление блоков
* **Lease Recovery**  - процедура восстановления  эксклюзивного доступа на запись в HDFS
* **Pipeline Recovery**- процедура восстановления пайплайна.

![[Pasted image 20220403235417.png]]

Диаграмма состояний и переходов каждой отдельно взятой реплики.
![[Pasted image 20220403235543.png]]


Вначале когда data node pipeline только организован, то реплика находится в состоянии init.
Как только начали поступать данные, реплика  переходит в состоянеие RBW= Replica Begin Written to 
Если всё хорошо, и сбоев нет, то реплика передёт в состояние finalized

Предположим что никто данные не заливает, но какой то сервер вышел из строя. В этот момент мы потеряли какие то реплики и их надо восстановить.
Соответственно берётся такая же реплика с ноды где она есть.
Сначала она так же будет в состоянии init.
А как только потекут данные перейдёт в состояние temporary.
Если всё зорошо, то она так же как и в прошлом состоянии перейдёт в состояние finalized.
Но если в период работы с временной репликой оборвалась связь или машина вышла из строя, то когда она вернётся к жизни, то такая реплика будет удалена с жеского диска.

В случае с RBW картина интересней.
Сценарий 1.
Что то отвалилось в период записи на диск или сломался сетевой буфер. Тогда мы отмечаем ошибку записи данных, закрываем сетевые tcp/ip соединения с соседями по пайплайну и спокойно сносим данные. У соседей есть процедура pipeline recovery, они эту ошибку заметят, увеличат счетчик generation step и займутся дозаписью данных в новой эпохе. 

Сценарий 2.
RWR = Replica Waiting to be Recovered

Машина или сервис datanode просто перезагрузилась и проблем работы с дисками или сетью просто не было. 
В этом случае все реплики в состоянии RBW переходят автоматически в состояние RWR. 
Дальше 2 сценария, 
Либо HDFS клиент успешно дозапишет данные на оставшиеся рабочие ноды, когда это произойдёт namenode вышлет указания для datanode пометить эту реплику устаревшей и данные будут зачищены (obsolete).
Либо HDFS клиент тоже сдохнет, и тогда такие реплики будут учавствовать в процедуре согласования консистентного набора данных для сохранения максимума данных этого чанка - RUR = Replica Under Recovery. 
 В таком случае клиент мертв и поддержку правильного generation step  возьмет на себя namenode. 

Процедура в RUR простая: если у тебя старый по отношению к другим репликам generation step, то удаление, если в период записи поломался диск или сетевые буферы - удаление.  
Если проблем никаких не было то в состояние finalized. 

С состояниями реплик разобрались, теперь переходим  в состояние блоков. 

![[Pasted image 20220404033538.png]]
Слева оригинальная диаграмма. с права упрощенная модель с основными переходами. 

Начали запись нового чанка - блок переходит в состояние init

Данные поехали - блок перейдет в состояние under construction

Восстанавливаемся после сбоев - under recovered

Клиент попросил закрыть файл или добавить в следующий чанк данных файл это означает что весь поток байт старого чанка он отправил в datanode pipline и получил плдтверждение по сети что всё хорошо. В этом случае блок перейдёт либо в состояние complete если он видел хотя бы одну реплику в состоянии finalized 
Иначе в состояние commited если данные на диск еще не записаны, но уже в сетевом буфере.


###  W1L107. Hadoop Sizing_ оценка вычислительных мощностей для хранения данных

Возьмем к примеру ребят из CERN они накопили 200 петабайт данных. Но все данные за раз они анализировать не планируют. 

Решили прикинуть, сколько денег надо заложить в бюджет, что бы выгрузить 10 петабайт данных в hadoop хранилище для удобной обработки и анализа данных в течении месяца. 

Есть 2 составляющие - это во первых хранилище для реплик, а во вторых - ram на namenode для хранения блоков. 

Закупаем партию жеских дисков - 2тб каждый. Учитываем что по умолчанию используется тройная репликация (на жестких дисках с учетом всех реплик по факту у нас будет хранится не 10 петабайт, а все 30.) это получается 15.000 жестких дисков.
Если кластер разворачивается на месяц, надо оценить сколько дисков за этот месяц сломается, что бы купить их про запас. 
Чтобы понять как это оценить идём на сайт backblaze.com со статистикой по дискам.
В среднем каждый день, на  127.500 жестких дисков вылетает 4.5 диска.
в нашем случае в день будет вылетать 0.5 диска.
За 30 дней вылетит штук 16. 
Если будут не очень удачные модели то можно получить аж 400 
умерших дисков.

А при высокой нагрузке вероятность их потери возрастает кратно.

На основе оценок jira issue средний размер блока о информации о 3х репликах - 150 байт. рамер чанка по умолчанию - blocksize - 128мб.

Итого 12гб на блоки  в лучшем случае. а если блоки меньше то еще больше
![[Pasted image 20220404042337.png]]

проблема мелких чанков называется small files problem. хадуп не любит маленькие файлы. 
С другой стороны, чем меньше чанки, тем быстрее их обрабатывать 
![[Pasted image 20220404042613.png]]

Основные ограничения на blocksize.

на каждые 16 гб оперативной памяти на namenode в предположении 150байт на блок получаем 115 миллионов чанков 
с учетом 3ной репликации при размере блока в 32мб. сохраняем в hdfs ~ 1.138 pb

Если ram на namenode не жмет, то уменьшать размер чанка до предела тоже нельзя, это связано с тем, что время доступа к части диска 0.2-0.8 мс. Т.е появляются накладные расходы на поиск данных на диске
![[Pasted image 20220404043421.png]]

Текущий индустриальный стандартный размер чанка - 128 мб


### W1L108. Namenode, Checkpoint Namenode и как теряют данные
Что происходит при выходе из строя namenode?
В версии 1.0 - всё плохо. вся система выходила из строя.

В хронологическом порядке:
Итак нам надо для обслуживания большого числа клиентов мы должны хранить всю метаинформацию в ram. 
При этом при загрузке сервера нам надо восстанавливать последнее актуальное состояние. Эта информация тоже должна где то хранится. 
Выгрузить дамп оперативки на хард - дорогая и медленная операция. 
Решение: мы записываем в файл не дамп оперативной памяти, а все транзакции на изменение любой метаинформации в распределённой файловой системе. 
Например a.txt переименовать в b.txt файл c.txt удалить итд.
![[Pasted image 20220404044834.png]]

и что бы ничего не пропустить следуем WAL - сначала пишем транзакцию в файл а затем отражаем изменение в оперативной памяти. 
Всё работает, но
Есть 2 проблемы:
1) могут поломаться жесткие диски. Решение: использовать еще одну файловую систему NFS - namenode file system
2) Скорость запуска namenode после сбоев. просто применить все изменения к оперативке может быть долго, если мы копили их неделями.

Что бы решить 2ую проблему, делают слепки оперативной памяти damp или snapshot. в гугле или яху их называют checkpoint. когда они есть то можно проигрывать изменения начиная с чекпоинтов.
Загвоздка - создание чекпоинта это дорогая операция. 
Поэтому что бы минимизировать нагрузку на namenode придумали
завести новый сервис, который называется checkpoint  namenode:

![[Pasted image 20220404045859.png]]

его задача простая:
он загружает последний чекпоинт с namenode ( его принято именовать fsimage) так же этот сервис загружает файл с транзакциями от момента создания чекпоинта (edits_logs)
оба этих файла грузит в оперативку, проигрывает все транзакции и создаёт бинарную версию слепка этой информации на жестком диске.
Результат отправляется обратно на primary namenode

Есть подводные камни: 
checkpoint namenode требует такой же объем оперативной памяти как и primary namenode и это нужно закладывать в бюджет .
Во вторых этот сервис получил неудачное название - secondary namenode.
Шпаргалка для понимания что где хранится:
![[Pasted image 20220404050715.png]]

**Следующий виток развития hdfs2.0**

Предложили 2 идеи. одна прижилась, другая нет

то что не вздетело:
HDFS Federation
Когда слишком много метаинформации и её приходится шардировать на разные устройства.
![[Pasted image 20220404050935.png]]


То что взлетело 
HDFS HA
Это HDFS который не выходит из строя при выходе из строя primary namenode
заводится дополнительная (standby NN)  которая подписана на все изменения транзакций и в любой момент может перехватить управление в случае поломки первой. 
![[Pasted image 20220404051134.png]]

Синхронизация достигается за счет легковесных сервисов journal nodes  их тоже заводят пачками что бы избежать проблем. 
![[Pasted image 20220404051440.png]]

**Следующий виток развития hdfs 3.0

![[Pasted image 20220404051619.png]]









