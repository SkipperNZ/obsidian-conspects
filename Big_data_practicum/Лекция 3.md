
[[Big_data practicum made]]



# Лекция 3
 Оптимизация MapReduce вычислений


###  W3L102. Streaming Word Count


Диагамма работы стриминговых mapReduce приложений:

![[Pasted image 20220419150949.png]]

Mapper  читает данные в цикле из stdin  и определяет как мы парсим этот вход на ключ-значение. 
По умолчанию - разделитель это знак табуляции
![[Pasted image 20220419151052.png]]
![[Pasted image 20220419151248.png]]
Дальше к этой паре мы должны применить функцию map
В отдельную функцию её не выносим, а реализуем прямо тут.
![[Pasted image 20220419151336.png]]
И определяем вывод данных. 
Аналогично входу - стандартный разделитель для хадупа - является знак табуляции
![[Pasted image 20220420070802.png]]

И если мы запустим только маперы, то на выходе получим файл, на каждый обработанный сплит данных.
![[Pasted image 20220420071406.png]]
Вот что нв выводе
![[Pasted image 20220420071518.png]]

Есть не очень нужные знаки пунктуации. Что бы от них избавится, можно воспользоваться регулярками
![[Pasted image 20220420071630.png]]

Теперь разберёмся с редьюсером. 
Запустим mapReduce без указания скрипта для обработки данных, так мы посмотрим что будет после шафл энд сорт 
![[Pasted image 20220420072227.png]]
на вход редьюсеру приходят данные отсортированные по ключам 
![[Pasted image 20220420072314.png]]

Агрегацию значений по этим ключам надо сделать самостоятельно. 
Наш скрипт преобразует вход следующего вида в агрегированную статистику.
Мы будем держать в памяти указатель обрабатываемой строки  и счетчик группы (указатель помечен стрелкой, а группа в пунктирной границе)
В зависимости от положения указателя, надо прописать наше поведение
![[Pasted image 20220420072542.png]]

Сначала парсим входные данные 
![[Pasted image 20220420073120.png]]
После этого надо понять где мы находимся 
если мы обрабатываем текущую группу, то мы просто увеличиваем счетчик.
![[Pasted image 20220420073212.png]]
Либо мы вышли за пределы текущей группы, тогда мы выводим аналитику обратно в хадуп через принт в stdout
Обратим внимание, что мы сбрасываем счетчик не в ноль, а в  первое значение строки группы 
И так же мы проверяем ключ на валидность (что бы инициализировать первый блок и не выводить пару none, 0)

![[Pasted image 20220420073338.png]]

И в конце нужно не забыть вывести последнюю обработанную группу. 
еще один иф нужен потому что на какой нибудь конкретный редьюсер данные могут вообще не приехать, если неудачная хеш функция по ключам, или очень много редьюсеров
![[Pasted image 20220420073905.png]]
целиком оно выглядит так:
![[Pasted image 20220420074105.png]]
Добавляем в конфиг запуска 
![[Pasted image 20220420074145.png]]
и получаем нужный ответ
![[Pasted image 20220420074217.png]]


### W3L103. Распределенный кеш (Distributed Cache)

Рассмотрим типовую задачу:
нужен срез, по частоте встречаемости по какому то заданному словарю. 
Мы можем запустить наш "ворд каунт" посчитать статистику по всем словам а затем grep'нуть по словарю, но это очень неэффективно.
![[Pasted image 20220420075027.png]]

По этому мы хотим написать такое mapReduce приложение, в которое словарь для фильтрации можно передать аргументом и использовать его внутри маппера
![[Pasted image 20220420075418.png]]
Для того, что бы словарь был доступен его надо прописать так
это называется "Положить данные в распределённый кэш хадуп"
![[Pasted image 20220420114055.png]]

Итак, разберёмся как оптимизировать yarn приложения и mapReduce в частности. 
Итак, когда мы запустили наше стриминговое mapReduce приложение то попросили его провести коммуникацию со всеми nodeManager на которых будут запущены воркеры нашего приложения, что бы разложить на этих серверах все необходимые файлы (в нашем случае mapper.py, reducer.py, vocabulary.txt).
![[Pasted image 20220420114230.png]]

На серверах может быть запущено несколько воркеров, и каждый из них получит доступ к пошареным ресурсам. Это как раз веменные данные которые будут хранится в noneHdfsStorage, в пространстве выделенном для всех временных данных всевозможных yarn приложений.
![[Pasted image 20220420114321.png]]

Какие плюсы:
Один раз скачали данные на какой либо сервер и все врокеры на нем (их может быть не один десяток) имеют доступ к ним по линковой ссылке без лишних обращений по сети.
Минусы: 
Данные должны быть неизменяемые, что бы гарантировать детерминизм исполнения.(а права доступа на запись есть поэтому просьба таким не промышлять)  

В распределённый кеш можно закладывать следующее:
файлы, архивы и библиотеки(в основном для джавистов)
архивы вообще суперудобная штука. 
Например: 
команда tar можно создать архив names.tar в котором будут лежать 2 файла (male.txt, female.txt)
![[Pasted image 20220420120325.png]]
для запуска стримингово yarn приложения  добавляется флаг 
-archives и путь до архива 
![[Pasted image 20220420120529.png]]
а все файлы из архива будут распакованы в папку, что бы избежать конфликта имен с имеющимися файлами в рабочей директории 
а название папки - полное название архива (включая .tar) 
![[Pasted image 20220420120655.png]]

![[Pasted image 20220420121024.png]]



### W3L104. Combiner

один из самых главных инструментов для оптимизации распределённых вычислений. 
Combiner - он позволяет совершенно бесплатно, одной строчкой кода, ускорить вычисления почти в 2 раза

Снова рассмотрим на примере word count:
Посмотрим на mapper
![[Pasted image 20220420121408.png]]
Видим супер неэффективность  того что все данные из маппера сначала сохраняются на жесткий диск, а потом еще и передаются по сети: 
![[Pasted image 20220420121532.png]]

Вот оптимизация, которую можно сделать внутри mapper'a
![[Pasted image 20220420121729.png]]

Уже будет работать быстрее, но всё равно не так быстро как с комбайнером.
вот сравнительные характеристики для word count
![[Pasted image 20220420121922.png]]

Собственно комбайнер агрегирует вывод маппера до того, как он будет передан редьюсеру. 
Причем делает он это за рамками функции map
![[Pasted image 20220420122123.png]]

Сигнатура комбайнера легко выводится из известных сигнатур маппера и редьюсера. 

Так как комбайнер может как включатся так и выключатся то нам нужнл гарантировать что бы его формат совпадал с форматом вывода маппера. и поскольку он отвечает за предварительную агрегацию данных, то его вход  полностью аналогичным входу редьюсера. 
![[Pasted image 20220420122332.png]]
в нашем случае если редьюсер сначала выводит слово, а потом число, то он полностью совпадает с типом данных на выходе из маппера. и поэтому можно смело применить комбайнер- равный редьюсеру.
![[Pasted image 20220420122643.png]]


Попробуем теперь посчитать что то более экзотичное: 
Мы хотим посчитать среднюю частоту встречаемости слова в статьях википедии.
Если слово - протеин встречается в статье википедии, то сколько раз в среднем, это слово в этой статье встретится. 

Попытка 1. 

маппер - пока не меняется
![[Pasted image 20220420123043.png]]

А вот на редьюсере надо усреднять. 
Добавлен новый счетчик - `article_count` который отвечает за подсчет числа статей, в котором это слово встретилось 
![[Pasted image 20220420123143.png]]

если мы запустим вычисления - то всё хорошо. 
Но если, по аналогии с word_count в качестве комбайнера будет использовать функцию reduce то  попадём в просак. 

Надо разделить подсчет числителя и знаменателя для нашего среднего. 

Маппер обновим так, что бы он в качестве значения выдавал  пару - число статей / частота встречаемости по каждому слову из статьи.

Редьюсер теперь считывает число статей из потока входа stdin
будет суммировать и использовать в качестве знаменателя при выводе. 
![[Pasted image 20220420123836.png]]

Комбайнер кастомизируется так как маппер выдаёт инт, а редьюсер всё таки флоат. 
![[Pasted image 20220420124144.png]]

Каким образом с помощью комбаина оптимизировать вычисление медианы:
![[Pasted image 20220420124306.png]]
Правильный ответ - никак. 


### W3L105. Управляем Shuffle & Sort с помощью Partitioner и Comparator

Еще раз взглянем на диаграмму 
![[Pasted image 20220420124610.png]]

По умолчанию ключом является всё, что находится до первого знака табуляции, а значением всё остальное, и если знака табуляции в строке не было, то none

Собственно "по умолчанию" мы можем менять 
Пойдём от простых примеров к сложным
Самый важный параметр, который мы можем контролировать - 
это `stream.num.map.output.key.fields`
В переводе - количество полей из вывода стримингово скрипта, которые мы будем считать ключем.
![[Pasted image 20220420125020.png]]
Например: 

![[Pasted image 20220420125256.png]]

В случае запуска со всеми флагами по умолчанию увидим, что все пользователи отсортированы только по годам.
![[Pasted image 20220420125419.png]]

Но если укажем этот длинный параметр в 2, то ключем считается год рождения пользователя + имя
![[Pasted image 20220420125615.png]]

Немного усложним пример, хотим отсортировать данные не по возрастанию года, а по убыванию.
Размер ключа не меняем, так же 2 колонки,
а вот порядок нужно изменить.

Для этого нам пригодится **компаратор**
Добавляем злоебучий длинный флаг и дополнительная кастомизация
![[Pasted image 20220420130044.png]]

Если забыли указать то, что у нас 2 ключа, и по умолчанию оно равно 1. 
То в итоге всё отработает, но не отсортируется по 2ой колонке 

Теперь разберёмся что такое **Partitioner**
Это инструмент для задания хеширования данных
Это очень крутой трюк для оптимизации join'а датасетов в спарк приложениях. 
Он как и компаратор работает только по части ключа. 

Допустим мы хотим похешировать данные по первой букве имени.
![[Pasted image 20220420130657.png]]
итак у нас вот такой ключ: `-k2.1,2.1`
`2.1` - говорит что мы читаем с первого символа 2ого поля включительно и до `2.1` (первого символа 2ого поля) а это и есть первая буква имени 
![[Pasted image 20220420131011.png]]

есть еще штуки: 
сепаратор помогает заменить знак табуляции на запятую если  у нас не tsv a csv данные 
![[Pasted image 20220420131100.png]]

Это грязный хак который неявно заменяет запятые на табуляцию
![[Pasted image 20220420131300.png]]

Когда в приложении задействован комбайнер, то оказывается что комбайнер для выхода наследует настройки редьюсера а не маппера и нужно определить еще 1 флаг.  
![[Pasted image 20220420131447.png]]

И еще 1 самый жОООский лайфхак:
Оказывается, что можно использовать кастомный сепаратор для выделения части ключа на уровне partitioner'а или компаратора
![[Pasted image 20220420131558.png]]

Например в колонке хранится не какое то простое поле а ip адрес разделённый точками. количество цифр разное
![[Pasted image 20220420131855.png]]
 поэтому что бы выделить сортировку по 2ому октету ip адреса, можем врубить сепаратор
![[Pasted image 20220420132031.png]]

Если не врубим такой сепаратор то, поскольку ключ простой, состоящий из первой колонки, то в хеш всегда будет попадать none и все данные приедут на лдин редьюсер

Обновлённая модель 
![[Pasted image 20220420132511.png]]



































