[[Big_data practicum made]]

![[nosql_cassandra.ipynb]]

# Лекция 9
**NoSQL поверх больших данных (Cassandra)**

Большие данные можно хранить не только в hadoop hdfs.


### W9L102. Зачем нужен NoSQL

NoSQL - термин, описывающий класс БД, имеющих архитектурные отличия от классических реляционных БД. Основными факторами развития NoSQL БД считаются:
(могут не выполнятся такие свойства как: атомарность, транзакционность, изоляция)
(часто под NoSQL подразумевают распределённые базы данных)
* Скорость чтения/записи
* объем данных 
* ACID не всегда нужен

**Пример**
Вы проектируете платформу сбора данных с различных датчиков автомобилей всего мира:
* Критична ли потеря одного события (нет)
* что нам важнее - консистентность данных или доступность системы? (доступность)
* Будут ли проблемы с сетью? (Да)
* сколько событий в секунду мы будем обрабатывать? (неизвестно)

Для этой задачи нам потребуется БД, которая:
* является гео распределённой 
* обеспечивает доступность данных при выходе из строя любого узла
* Продолжает работу при нарушении сетевой связанности между любыми узлами
* Умеет горизонтально масштабироваться


### W9L103. CAP теорема Брюера
В любой распределённой БД возможно гарантировать выполнение только 2х из трех свойств:
* Consistency
* Availability
* Partition tolerance

**Consistency**
Результат любого запроса проявляется везде и сразу после того, как мы получили подтверждение от узла о его выполнении
**Availability**
Любая доступная нода должна ответить на запрос.
**Partition tolerance**
Система продолжает работать в условиях нарушения сетевой связности.

**И что это означает?**

**СА системы**
При возникновении проблем все ноды перестают обрабатывать запросы, но зато все консистентно. 
**СР системы**
В случае проблем никто не гарантирует доступность данных. 
**АP системы**
Система будет доступна даже после ядерного апокалипсиса, но некоторое время может возвращать не то, что вы ожидаете.



###  W9L104. Архитектура Cassandra

Cassandra - AP система в теореме CAP. На практике это означает: 
* высокая доступность данных (можем настроить её таким образом что бы она возвращала данные даже когда доступна из всего кластера только одна нода)
* нет транзакций (не совсем, есть легковесные транзакции, нет возможности выполнить 2 запроса подряд в базу с гарантией что между ними никто по середине не встроится и не запишет туда что то своё)
* можно строить гео-кластера(Можем строить один или несколько кластеров из колец касандры, каждая из которой будет расположена в 1 датацентре) 
* слабая согласованность (eventual) (консистентность, каждая запись данных может проявится не сразу а спустя какое то время микро-мили секунды)
* линейная масштабируемость (нет никаких мастер/дата нод, все узлы идентичны и каждый занимается тем же чем и остальные)
* высокая пропускная способность (особенно на запись)(быстрее чем mongoDB, но у монго меньше ограничений) (Касанндра для очень быстрых распределённых систем)

Cassandra имеет симметричеую архитектуру. Каждый узел отвечает за хранение данных, обработку запросов и состояние кластера. 
Расположение данных определяется значением хеш функции от Partition key.
Высокая доступность данных обеспечивается за счет репликации.
![[Pasted image 20220605175432.png]]

(Расположение данных определяется путем подсчета murmur3 хеша от ключа в наших данных. Каждая наша строка данных будет иметь некий ключ, от него будет считаться хеш, и в зависимости от того в какую ноду попадает хеш, там и будет сохранена данная строчка (в реальности немного сложнее но в целом так))

Поскольку все узлы в касандре идентичны, то принято называть кластера касандры - кольцами касандры.
Когда мы записываем данные в касандру, мы подсчитываем хеш, в зависимости от него данные записываются в соответствующий узел. И для обеспечения высокой доступности данных у нас есть репликация(данные записываются не на один узел е еще на несколько следующих узлов которые идут следующие в кольце)
Количество узлов на которых записываются один элемент данных - называется уровнем репликации.
![[Pasted image 20220605180917.png]]


### W9L105. Подготовка данных

Будем использовать python и библиотеку casandra.
Так же будем использовать утилиту `cqlsh` которая поставляется вместе с касандрой и позволяет выполнять различные сикуел запросы из командной строки.

Базовая настройка подключения к кассандре из питона:
```python 
from cassandra.cluster import Cluster
from cassandra.query import dict_factory
from tabulate import tabulate

cluster = Cluster(['brain-node1'])
session = cluster.connect()
session.row_factory = dict_factory
```

Вспомогательная функция для красивого вывода данных на экран
```python 
def print_table(data):
    print(
        tabulate(
            data,
            tablefmt="pretty",
            headers="keys",
            showindex="always",
            numalign="right",
            stralign="right")
    )
```

Теперь нужно создать 2 вещи.
1 - keyspace (в касандре это примерно то же что и база данных в реляционках, это логическое объединение таблиц, на основе которого мы делаем глобальные настройки, например на уровне keyspace мы задаем репликации)

Тут мы создаем кейспейс который называется тест и говорим что все данные которые мы будем записывать  в этом кейспейсе имеют уровень репликации 3.
```python 
create_keyspace = \

"""
CREATE  KEYSPACE IF NOT EXISTS test
WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 3}
"""

session.execute(create_keyspace)
```

Создадим таблицу
указываем в каком кейспейсе мы создаем таблицу, указываем имя и набор колонок. 
(колонки которые влияют на партиционирование и кластеризацию, они называются ключевые. и есть просто колонки, содержащие данные)
```python 
create_table = \

"""
CREATE TABLE IF NOT EXISTS test.cars0 (
    brand text PRIMARY KEY,
    model text,
    engine text,
    drive_wheel text,
    turbo boolean,
    acceleration float
)
"""

session.execute(create_table)
```

Теперь запишем туда данные. 
В качестве данных некий синтетический датасет. Он создаётся из длинных листов и писать его тут смысла нет, проще глянуть ноутбук. 
А записывается в базу он так:
```python 
insert_cars = \
"""
INSERT INTO {keyspace}.{table_name} (brand, model, engine, drive_wheel, turbo, acceleration)
VALUES (%s, %s, %s, %s, %s, %s)
"""

```

И функция которая пишет эти данные в таблицу:
```python 
  
def write_data(keyspace, table_name, num_rows):
    for i in range(0, num_rows):
        data = (
            random.choice(brands),
            random.choice(models),
            random.choice(engines),
            random.choice(wheel_drive),
            random.choice(turbo),
            float(random.choice(acceleration))
        )
        session.execute(insert_cars.format(keyspace=keyspace, table_name=table_name), data)
    print("Written {n} rows".format(n=num_rows))
    
def truncate_table(table_name):
    truncate_query = "TRUNCATE TABLE test.{table_name}"
    session.execute(truncate_query.format(table_name=table_name))
```

выполняем запись.
```python 
write_data("test", "cars0", 1000)
```

Теперь прочитаем:
```python 
select_cars = \
"""
SELECT * FROM test.cars0
"""

rows = session.execute(select_cars)
print_table(rows)
```
![[Pasted image 20220606040938.png]]
Всего таким образом прочитались 63 строки, а писали мы 1000.
Тут нет ошибки. В касандре ключевые колонки очень важны и ключевым образом влияют на то как мы записываем данные.
В каческве ключа мы используем бренд, всего было 64 возможных бренда и поэтому следующие записи перезаписывали предыдущие.


### W9L106. Модель данных Cassandra
В Cassandra существует три основных типа колонок:
- Обычные колонки
	 + опциональны(создав можем заполнять или не заполнять null)
	 + могут быть иметь любой тип из поддерживаемых
	 + являются nullable
	 + не могут выступать в качестве условия фильтрации
	 + можно добавлять новые и удалять колонки из таблицы (Делается налету)

- Проиндексированные обычные колонки (для обычной колонки можно построить secondary индекс но лучше этого избегать)
	+ могут выступать в качестве условия фильтрации

- Partition key (одна или несколько колонок)(определяют физическое расположение данных на ноде кластера)
	 + обязателен
	 + порядок (если используется несколько partition key)
	 + одна или несколько колонок
	 + определяет физическое расположение данных на кластере
	 + может выступать в качестве условия фильтрации с предикатами: =, IN
	 + не все типы данных поддерживаются (скалярные типы а не составные)

- Clustering key (работают вместе с партишн ключами и позволяют разбить таблицу на блоки)(определяют сортироку данных в каждой партиции)
	 + опционален
	 + одна или несколько колонок
	 + порядок (если используется несколько clustering key) имеет значение
	 + определяет расположение данных внутри партиции
	 + может выступать в качестве условия фильтрации с предикатами =, IN при соблюдении порядка следования*
	 + последний clustering key в запросе может выступать в качестве условия фильтрации с предикатами <, >, !=, =, IN


Важно:
- строки внутри партиций отсортированы по clustering key
- composite key = partition key + clustering key
- composite key является уникальным ключом колонки
- в одной партиции не может быть более 2kkk строк


**Выводы:**
- в реляционных БД модель данных определяется, исходя из структуры данных
- в Cassandra модель данных определяется, исходя из запросов к данным
- В Cassandra данные обычно хранят в денормализованном виде

В кассандре принято под каждый запрос делать отдельную таблицу.


### W9L107. Чтение и фильтрация данных в Cassandra
Для начала будем выполнять простые селекты и срезы по колонкам.
Partition key может выступать условием с предикатами =, IN:
Срез по колонке бренд = audi
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars0 WHERE brand = 'Audi'"
```
все отработало очень быстро
![[Pasted image 20220606044106.png]]

Так же работает хорошо и быстро
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars0 WHERE brand IN ('Audi', 'BMW')"
```
![[Pasted image 20220606044313.png]]

Фильтровать данные по обычной колонке нельзя:
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars0 WHERE drive_wheel = 'front'"
```
![[Pasted image 20220606044354.png]]

Но если очень хочется, то можно: (не гарантирован быстрый ответ)
(кассандре придётся перебирать все партиции на всех узлах и искать строчки в которых колонка драйв вилл имеет значение фронт)
```python 
# В большинстве случаев, использование ALLOW FILTERING - это антипаттерн

!cqlsh brain-node1 -e "SELECT * FROM test.cars0 WHERE drive_wheel = 'front' ALLOW FILTERING"
```
![[Pasted image 20220606044616.png]]

Вернемся к DDL таблицы cars0:

```
CREATE TABLE IF NOT EXISTS test.cars0 (
    brand text PRIMARY KEY,
    model text,
    engine text,
    drive_wheel text,
    turbo boolean,
    acceleration float
)
```
В данной таблице только одна колонка является единственным partition key - `brand`. Поэтому, сколько бы мы данных не записали, количество строк в таблице будет ограничено размером массива `brands`, остальные строки будут перезаписываться.

```python 
len(brands)
```
![[Pasted image 20220606044754.png]]

При необходимости мы можем очистить таблицу cars0:
```python 
truncate_table("cars0")
```


Создадим и наполним новую таблицу cars1, в которой ключами будут две колонки `brand` и `model`:
```python 
create_table = \
"""
CREATE TABLE IF NOT EXISTS test.cars1 (
    brand text,
    model text,
    engine text,
    drive_wheel text,
    turbo boolean,
    acceleration float, PRIMARY KEY (brand, model)
)
"""

session.execute(create_table)
truncate_table("cars1")
write_data("test", "cars1", 1000)
```


Прочитаем все данные из этой таблицы и убедимся, что их больше `len(brands)`
```python 
select_cars = \
"""
SELECT * FROM test.cars1;
"""

rows = session.execute(select_cars)
print("Table contains {n} rows and brands has length of {m}".format(n=len(list(rows)), m=len(brands)))
```
![[Pasted image 20220606045043.png]]

Выведем первые 5 строк на экран. Красным цветом выделен partition key, голубым - clustering key:
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars1 LIMIT 5"
```
![[Pasted image 20220606045226.png]]

Фильтровать данные запросы здесь можно:
- по полю `brand`
- по полю `brand` и полю `model`

Вот это работает быстро  достаем всю партицию целиком и показываем первые 5 
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars1 WHERE brand = 'Chrysler' LIMIT 5"
```
![[Pasted image 20220606045414.png]]

Тоже быстро.
Достанет партицию крайслер, а потом в ней возьмет строки у которых модель = альфа
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars1 WHERE brand = 'Chrysler' AND model = 'alpha'"
```
![[Pasted image 20220606045549.png]]

Фильтровать данные только по полю `model` нельзья:
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars1 WHERE model = 'alpha'"
```
![[Pasted image 20220606045712.png]]

Создадим еще одну таблицу, используя колонки `brand`, `model`, `engine`, `acceleration` в качестве ключей:
```python 
create_table = \
"""
CREATE TABLE IF NOT EXISTS test.cars2 (
    brand text,
    model text,
    engine text,
    drive_wheel text,
    turbo boolean,
    acceleration float, PRIMARY KEY ((brand, model), engine, acceleration)
)
"""

session.execute(create_table)
truncate_table("cars2")
write_data("test", "cars2", 10000)
```

![[Pasted image 20220606050046.png]]


Изучим структуру ключей в таблице:
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 LIMIT 5"
```
![[Pasted image 20220606050240.png]]

Возможные варианты фильтрации:
- по колонкам `brand`, `model`
- по колонкам `brand`, `model`, `engine`,
- по колонка `brand`, `model`, `engine`, `acceleration`

Важно:
- фильтрация по колонкам `brand` и `model` возможна только используя условия = и IN
- фильтровать <, >, != можно только по последнему кластерному ключу в запросе


Таким образом, работать будут следующие запросы:
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi'"
```
![[Pasted image 20220606050421.png]]


```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi' and engine = 'electric'"
```
![[Pasted image 20220606050452.png]]

```python 
!cqlsh brain-node1 -e \
    "SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi' and engine = 'electric' \
    AND acceleration > 10"
```
![[Pasted image 20220606050549.png]]


Запросы ниже работать не будут:
```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE model = 'phi'"
```

```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE engine = 'electric'"
```
Еще нельзя пропускать кластеринг ключи
```python 
!cqlsh brain-node1 -e \
    "SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi' \
    AND acceleration > 10"
```

Выводы:
- структура таблицы в БД зависит от запросов к ней
- нельзя пропускать (слева направо) ключи при фильтрации, но можно опустить последние n кластерных ключей
- нельзя фильтровать по одному из partition keys
- нельзя фильтровать по обычным колонкам (если она не проиндексирована)
- фильтровать c использованием <, >, != можно только по последнему кластерному ключу в запросе



### W9L108. Удаление данных в Cassandra
Для изучения запросов на удаление данных будем использовать таблицу `cars2`

Для начала, добавим в нее данных:
```python 
write_data("test", "cars0", 10000)
```


```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606051019.png]]

Работает так же как селект
```python 
!cqlsh brain-node1 -e "DELETE FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi' \
    AND engine = 'diesel' AND acceleration > 1"
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606051138.png]]

```python 
!cqlsh brain-node1 -e "DELETE FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi' \

    AND engine = 'petrol'"

!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606051229.png]]

И всю партицию целиком
```python 
!cqlsh brain-node1 -e "DELETE FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"

!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606051302.png]]

Выводы:
- удалять можно одну строку, указав весь composite key
- удалять можно группу строк, указав все partition key и часть clustering key
- удалять можно партицию целиком


### W9L109. Запись и изменение данных в Cassandra

делается это с помощью операций INSERT и UPDATE
Делая ту или иную операцию, мы всегда записываем новую строку в таблицу кассандра а старая будет помечатся как невалидная и со временем удалится физически.

Для изучения запросов на удаление данных будем использовать таблицу `cars2`

Для начала, добавим в нее данных:

```python 
write_data("test", "cars2", 10000)
```

```python 
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606051841.png]]


```python 
!cqlsh brain-node1 -e "INSERT INTO test.cars2 (brand, model, engine, acceleration, drive_wheel, turbo) \
    VALUES ('Audi', 'pi', 'electric', -1, 'all', false)"
    
!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606051959.png]]


Как обновить строку
```python 
!cqlsh brain-node1 -e "UPDATE test.cars2 SET turbo = true \
    WHERE brand = 'Audi' AND model = 'pi' AND engine = 'electric' AND acceleration = -1"

!cqlsh brain-node1 -e "SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'"
```
![[Pasted image 20220606052123.png]]

Выводы:
- под капотом INSERT и UPDATE являются единой операцией, которая называется UPSERT
- при использовании INSERT и UPDATE единственным требованием является указание всего composite key
- используя стандартный SELECT, INSERT и UPDATE, нельзя обеспечить атомарное изменение поля строки (см. LWT https://docs.datastax.com/en/cql-oss/3.3/cql/cql_using/useInsertLWT.html)


### W9L110. Spark Cassandra Connector
Разберём запись и чтение данных в касандру из спарка. 

https://github.com/datastax/spark-cassandra-connector

Для работы с Cassandra в Spark необходимо добавить:
```
--packages com.datastax.spark:spark-cassandra-connector_2.11:2.4.3 \
--conf spark.cassandra.connection.host=brain-node1 \
```

Указываем формат и опции и далее работаем как с обычным датафреймом. 
```python 
from pyspark.sql.functions import *

df = spark.read \
            .format("org.apache.spark.sql.cassandra") \
            .options(table="cars0", keyspace="test") \
            .load()
df.printSchema()

df.show()
```
![[Pasted image 20220606190358.png]]


Спарк очень быстро пишет данные в касандру а вот чтение непростое. 

Применяя фильтр, следует помнить о структуре ключей. Если фильтр составлен правильном, то сработает predicate pushdown:
(если указать все правильно то запрос пойдет быстро в касандру)
```python 
filtered_p = df.filter(col("brand") == "Audi")
filtered_p.explain(True)
filtered_p.show()
```
![[Pasted image 20220606190719.png]]

Predicate pushdown сработает и в этом случае, но под капотом будет использован ALLOW FILTERING, т.к. фильтрация осуществляется не по ключу:
```python 
filtered_p = df.filter(col("engine") == "petrol")
filtered_p.explain(True)
filtered_p.show()
```
![[Pasted image 20220606190852.png]]


Однако, если сделать более сложный фильтр, то predicate pyshdown не произойдет. В этом случае spark прочитает таблицу ЦЕЛИКОМ. Это следует помнить при работе с большими таблицами:
```python 
filtered_p = df.filter(length(col("brand")) > 4)
filtered_p.explain(True)
filtered_p.show()
```

Запись осуществляется по аналогии с другими форматами:
```python 
filtered_p \
    .write \
    .format("org.apache.spark.sql.cassandra") \
    .options(table="cars1", keyspace="test").mode("append").save()
```


**Full List of Predicate Pushdown Restrictions**

1. Only push down no-partition key column predicates with =, >, <, >=, <= predicate
2. Only push down primary key column predicates with = or IN predicate.
3. If there are regular columns in the pushdown predicates, they should have
   at least one EQ expression on an indexed column and no IN predicates.
4. All partition column predicates must be included in the predicates to be pushed down,
   any part of the partition key can be an EQ or IN predicate. For each partition column,
   only one predicate is allowed.
5. For cluster column predicates, only last predicate can be RANGE predicate
   and preceding column predicates must be EQ or IN predicates.
   If there is only one cluster column predicate, the predicates could be EQ or IN or RANGE predicate.
6. There is no pushdown predicates if there is any OR condition or NOT IN condition.
7. We're not allowed to push down multiple predicates for the same column if any of them
   is equality or IN predicate.

https://github.com/datastax/spark-cassandra-connector/blob/master/doc/14_data_frames.md#full-list-of-predicate-pushdown-restrictions


Выводы:

- используя cassandra в spark, следует помнить о структуре композитного ключа и особенностях составления запросов к БД
- конфигурация БД указывается в параметрах `spark-submit` при запуске приложения
- для работы с Cassandra необходимо добавить зависимость с https://mvnrepository.com




