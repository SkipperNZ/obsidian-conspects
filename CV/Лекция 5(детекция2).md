[[CV]]




# Лекция 5

В этой лекции речь пойдёт об одношаговых подходах в детекции
**Single Shot Approaches**


Основная идея такая:
отказываемся от region proposals и Rol poolong. 
Одна сеть для предсказания классивикации и регрессии сразу для каждой возможной локации (anchor-boxes)

не стоит путать с one-shot learning


### Single Shot Detector (SSD)
(уже устарела)

1) Концепция Prior boxes (то же что и анкер боксы)
2) Входное изображение фиксированного размера обрабатывается VGG16 до  conv5_3. Результат передаётся классификатору.
3) Делэйтед свертка(как на картинке с низу где через 1 идут поля разрежено) с dilation=6 to conv5_3 для значительного улучшения рецептивного поля.
4) Применяйте дополнительные слои, чтобы предсказывать более крупные боксы. 
5) Бысрая (~59 fps for SSD300 and 16 fps for SSD512)

![[Pasted image 20220430133921.png]]

![[Pasted image 20220430133942.png]]


### YOLO (You Only Look Once)
(уже устарела)

1) Тензор размера SxSx(B\*5+C). B - количество анкор боксов в каждой ячейке. С - количество классов.
Для картинки внизу (B=2, S=7, C=20)
2) работает в реалтайме
3) “Darknet” фреймворк

есть куча дальнейших модификаций YOLO
1.  YOLO v2 (a.k.a. YOLO9000): more classes.
2.  YOLO v3: log. reg. for each class. Helps with overlapping objects. Multiscale anchor boxes.
3.  YOLO v4: lots of small improvements 
4.  YOLO v5: very good quality/performance balance.
 
![[Pasted image 20220430141008.png]]

![[Pasted image 20220430141027.png]]

### YOLO v3
![[Pasted image 20220430141637.png]]

![[Pasted image 20220430141655.png]]


### RetinaNet
(Вот тут уже важно)

1) Основана на - ResNet
2) Feature Pyramid Network **(FPN)**
3) FocalLoss против дисбаланса классов. 

**Focal Loss**

Проблема: дисбаланс классов. (когда в выборке очень много примеров одного класса и мало другого) 
В детекции эта проблема берётся  из за того, что самый дисбалансированый класс это фон-background 
В каждом суперпикселе предсказаный тензор с признаками - это какая то вероятность нахождения объектов в каком либо анкербоксе, а большая часть анкербоксов ничего в себе не содержет.
Это плохо тем, что градиент после прогона картинки сильно зашумлён,  из за того что суммарный вклад фона очень большой.

Выход вместо Cross Entropy (CE) использовать Focal Loss (FL)

Cross Entropy :
$$\large
CE(p,y) = CE(p_{t}) = -\log(p_{t})
$$

Focal Loss:
$$\large
FL(p_{t}) = -(1-p_{t})^{\gamma}\log(p_{t})
$$


При этом 
![[Pasted image 20220430143032.png]]
p - вероятность которую мы предсказали.
y - метка класса.

как оно выглядит на графике:
Синий график - кросс-энтропия  или фокал лосс с гамма = 0 
Увеличивая гамму видим как все больше график прижимается к оси
И когда сеть хорошо обучается предсказывать верно бекграунды, то вклад у этого в лосс будет небольшой.
а если сеть сильно ошибается то наоборот.
![[Pasted image 20220430143315.png]]


**Feature Pyramid Network (FPN)**

Схема такая:
Вот мы получаем разного уровня тензоры, по высоте и ширине, при прогоне через сверточную сеть. 
После чего мы делаем такую штуку (справа)
Берем самый позний тензор, и используем его для предсказания  классификации и баундинг бокс регрессии 
далее интерполируем его по ширине и высоте(делаем больше, такой как предыдущий тензор) и складываем их.
итд.

Идея - более высокоуровневые признаки для меньших масштабов.
![[Pasted image 20220430143923.png]]

Есть разные вариации FPN

![[Pasted image 20220430144830.png]]


BiFPN используется в детекторе, который называется EfficientDet

### EfficientDet
![[Pasted image 20220430145803.png]]

1) Основан на **EfficientNet**
2) Bi-FPN

EfficientNet
1) найден с помощью NAS (Neural Architecture Search)
2) Compound scaling

![[Pasted image 20220430150234.png]]



##  Cascaded detectors
Очень быстрые но не такие точные.
Идея: 
Обрабатываем обрабатываем изображение не одной тяжелой нейросетью, а несколькими маленькими, каждая из которых довольно быстрая и каждая следующая модель опирается на результаты предыдущей. 

Примеры:
1) Viola-Jones (Classic) не использует нейросети
2) MTCNN мульти таск с н н

### MTCNN
Каскадный детектор с тремя сетями в каскаде
3 этапа:
1) PNet - FCN, генерирует Proposals. (полносвёрточная сеть)
2) RNet - Уточняем proposals. 
3) ONet - дополнительно уточняет обнаружение и выводит ключевые точки лиц (самая тяжелая сеть)

![[Pasted image 20220430151156.png]]

![[Pasted image 20220430152055.png]]


Детали **MTCNN**:

1) Fast: About 10-20 ms. (GPU) on a 600x600 image for full detection pipeline.
2) A good choice for most Facial Recognition algorithms.
3) Quality is slightly worse than most others “more complex” detection architectures.


Советы по повышению качества детекции:

1. Больше аугментаций 
	1.1) Классические (mirror flips, hue/gamma modification, etc.)
	1.2)  Любые которые меняют форму размер расположение баундинг боксов rotations, scaling, random cropping, jittering
2. Улучшеную бекбон архитектуру.
3. SoftNMS
4. Smooth-L1 loss for bbox regression
5. IoU Loss, Repulsion Loss

![[Pasted image 20220430153234.png]]


### More Architectures

1.  EfficientDet - EfficientNet as a backbone (NAS).
2.  FCOS, CenterNet - predict “centerness” of the boxes. 
3.  CascadeRCNN - many heads for different IoU thresholds, resampling.
4.  DETR - Transformer on CNN features.
5.  YOLOv5


















