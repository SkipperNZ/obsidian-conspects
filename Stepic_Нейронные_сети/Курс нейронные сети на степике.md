

https://editor.codecogs.com/ - куча авто операторов на $\LaTeX{}$


```toc
```

# Нейронные сети на степике

## Основы линала

### Векторы

1. Умножение на константу
$$\large x\cdot c = 
\begin{bmatrix}

x_1\cdot c\\
x_2 \cdot c \\
...\\
x_n \cdot c \\

\end{bmatrix}
$$
2. Сложение векторов
Если размерности одинаковые
$$\large x + y = 
\begin{bmatrix}

x_1 + y_1\\
x_2 + y_2 \\
...\\
x_n + y_n \\

\end{bmatrix}
$$
3. Вычитание векторов
(аналогично сложению)

4. Взятие длины вектора
$$ \large
|a| = \sqrt{x^2_1 + x^2_2 + ... + x^2_n}
$$
5. Скалярное произведение
$$ \large
a \cdot b = x_1y_1 + x_2y_2 +...+x_ny_n
=|a|\cdot|b|\cdot \cos{\alpha}
$$

6. Векторное произведение
$$\large
a \times b
$$
его в этом курсе не рассматриваем.


### Матрицы
 1) Матрицы можно складывать если размерности совпадают, поэлементно.
 
2) Матрицу можно умножить на число. Так же каждый элемент умножается на это число.

3)  Умножение матриц.

Количество столбцов в первой матрицы должно равняется количеству рядов во второй.
 $$\large
A_{n\times m} \cdot B_{m\times k} = C_{n\times k}
 $$
 Внутренние размерности схлопываются, а внешние соединяются.
 
В результате получается матрица $C$ в которой элемент $C_{ij}$ это
скалярное произведение строк $A_i$ и $B_j$ 


![](https://ucarecdn.com/152b53b1-4372-411d-8e15-c4126198f138/)

Единичная матрица E (квадратная с единицами на диагоналях.
$$
E \cdot A = A
$$
$$
A \cdot E = A
$$

4) Транспонирование
Это то же самое что и взять строки и записать их в столбик.
$$
(A^T)^T = A
$$
$$
(A+B)^{T}= A^T+B^T
$$
$$
(\lambda B)^{T}=\lambda (B)^T
$$
$$
(A\cdot B)^{T}= B^{T}\cdot A^T
$$
5) Взятие обратной матрицы.

Для квадратной матрицы (n x n) может найтись обратная матрица такого же размера, что 
$$
A \cdot A^{-1} = A^{-1} \cdot A = E
$$
Для неквадратных матриц, обратных вообще не существует.

Свойства операций взятия обратной матрицы:
$$
(A \cdot B)^{-1} = B^{-1} \cdot A^{-1}
$$
$$

(k \cdot B)^{-1} = k^{-1} \cdot B^{-1}
$$
$$
(A^T)^{-1} = (A^{-1})^T
$$
$$
E^{-1} = E
$$

### numpy

Создание матрицы и просмотр формы
```
a = np.array([[1,2,3], [4,5,6]])
a.shape
```

Создание массива:
* `array(object)` - n-мерный массив из любой (возможно, вложенной) последовательности
* `eye(N, M=N, k=0)` - единичная матрица с N строками. 
Число столбцов M по умолчанию равно N. k — сдвиг диагонали.
* `zeros(shape)` - массив нулей.
* `ones(shape)` - массив единиц.
* `full(shape, fill_value)` - массив указанной формы  заполненный fill_value

**Как получить доступ к элементу массива или выбрать кусок массива:**

* `a[start:stop:step]` выбирает элементы из `a` с индексами от `start` до `stop` с шагом `step`. так же можно опустить все лишние индексы `a[:]`.
* отрицательные индексы;
-  `a[..., 1]` выбирает элементы с любым индексом в первом измерении и с индексом, равным 1, во втором измерении:  `a[:, 1]` оказывается эквивалентно `a[..., 1]`;
- можно указать индексы сразу в нескольких измерениях, указав их через запятую в квадратных скобках (как `a[..., 1]` в примере выше).

### Основные методы ndarray
**Форма массива**
-   `a.flatten()` — превращает массив в одномерный.
-   `a.T` или `a.transpose(*axes)` — транспонирование (или смена порядка осей в случае, когда размерность массива больше двух).  
-   `a.reshape(shape)` — смена формы массива. Массив "распрямляется" и построчно заполняется в новую форму.

**Базовые статистики**

* `a.min(axis=None)`, `a.max(axis=None)`, `a.mean(axis=None)`, `a.std(axis=None)` — минимум, максимум, среднее арифметическое и стандартное отклонение вдоль указанной оси. По умолчанию ось не указана и статистика считается по всему массиву. `a.argmin(axis=None)`, `a.argmax(axis=None)` — индексы минимального и максимального элемента. Пример:

-   `a.sum(axis=None)`, `a.prod(axis=None)` — сумма и произведение всех элементов вдоль указанной оси. `a.cumsum(axis=None)`, `a.cumprod(axis=None)` — частичные суммы и произведения (для $(a_1,⋯,a_n)(a1​,⋯,an​)$  вектор частичных сумм — это $(a_1,a_1+a_2,⋯,a_1+⋯+a_n)(a1​,a1​+a2​,⋯,a1​+⋯+an​))$.
  грубо говоря каждое следующе значение, это сумма всех предыдущих что были в строке/столбце. результат матрица того же размера

  **Линейная алгебра**

Пакет `numpy.linalg` содержит большую часть стандартных операций и разложений матриц. Некоторые самые популярные функции вынесены в корень пакета NumPy.

-   `a.dot(b)` — матричное произведение двух массивов (размерности должны быть согласованы),
-   `linalg.matrix_power(M, n)` — возведение матрицы `M` в степень `n`,
-   `a.T` — транспонирование
-  `linalg.norm(a, ord=None)` — норма матрицы `a`, по умолчанию норма Фробениуса для матриц и L2-норма для векторов; подробное описание возможных норм — в [справке](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm),
-   `linalg.inv(a)` — матрица, обратная к `a` (если `a` необратима, выбрасывается LinAlgError; псевдообратная считается через `linalg.pinv(a)`)
  
Подробные описания с указанием полного списка аргументов, а также описания всех остальных функций находятся на сайте проекта [NumPy](http://docs.scipy.org/doc/numpy/reference/index.html).

-   `map(f, iterable, …)` — встроенная функция языка Python, возвращает результат поэлементного применения функции `f` к элементам последовательности `iterable`; если `f` принимает несколько аргументов, то на вход должно быть подано соответствующее число последовательностей: результатом `map(f, x, y, z)` будет итератор, возвращающий поочерёдно `f(x[0], y[0], z[0])`, `f(x[1], y[1], z[1])`, `f(x[2], y[2], z[2])` и так далее; результат применения f к очередному набору аргументов вычисляется только тогда, когда требуется использовать этот результат, но не ранее, подробнее и короче [в справке](https://docs.python.org/3/library/functions.html#map);

**Чтение данных из файла**

```
sbux = np.loadtxt("sbux.csv", usecols=(0,1,4), skiprows=1, delimiter=",", dtype={'names': ('date', 'open', 'close'), 'formats': ('datetime64[D]', 'f4', 'f4')})
```

* `"sbux.csv"` — имя файла (или сюда же **можно передать объект файла**, такой пример вы увидите в следующей задаче урока), из которого считываются данные.
* `usecols` — список колонок, которые нужно использовать. Если параметр не указан, считываются все колонки.
* `skiprows` — количество рядов в начале файла, которые нужно пропустить. В нашем случае пропущен ряд заголовков. По умолчанию (если значение параметра не указано явно) `skiprows = 0`.
* `dtype` — словарь из названий колонок (переменных) и типов хранящихся в них значений. NumPy использует свою собственную систему типов, и названия именно этих типов нужно указать. По умолчанию функция попытается самостоятельно угадать, какому типу принадлежат подаваемые на вход значения.

### Линал в деле (упражнения на numpy)

пока скипнул.


## Перцептрон и градиентный спуск

$$\large
\begin{equation*}
f(x, \omega, b) = 
\begin{cases}
1 \: если \: \sum\limits_{i=1}^{n}\omega_{i}*x_{i}+b>0 \\
0 \: если \: \sum\limits_{i=1}^{n}\omega_{i}*x_{i}+b\leq0

\end{cases}
\end{equation*}
$$

Где $\omega$ - вектор весов,
*x* - вектор входных активаций
*b* - смещение (bias)
$f(x, \omega, b)$ - выходная активация перцептрона

Активационная функция(из задания)
$$f(t) = \left\lbrace\begin{array}{t} 1,&\text{ если } t > 0, \\ 0 &\text{иначе}\end{array}\right.$$

Обучается перцептрон так:
```python
perfect = False
while not perfect:
    perfect = True
    for e in examples:
        if Predict(e) != Target(e):
            perfect = False
            if Predict(e) == 0:
                w = w + e # просто складываем вектор весов и вектор 
            if Predict(e) == 1:
                w = w - e
```
 
проблема перцептрона - он не может справится с XOR.

### Другие искусственные нейроны


1) Линейный нейрон
2) Сигмоидальный нейрон (похож на перцептрон)
3) Гиперболический тангенс (tanh)
4) ReLU
5) softplus



**Линейный нейрон**
$$
f(x, \omega, b) = \sum\limits_{i=1}^{m}w_{i}\cdot x_{i}+b
$$
$f(x, \omega, b)$ - выходная активация нейрона
$\omega$ - вектор весов,
*x* - вектор входных активаций
*b* - смещение (bias)

Грубо говоря, просто возвращает значение аргумента.

Еще немножко нумпая для задачки:
* Форма (m,1) - двумерный (имеющий два измерения) массив с m строк и 1 столбцом;
* форма (1,m) - двумерный (имеющий два измерения) массив с 1 строкой и m столбцов;
* форма (m,) - **одномерный** массив, содержащий m элементов



**Перцептрон**
Его очень важное непрерывное усовершенствование - **сигмоидальный нейрон**
График активационной функции - ступенька с разрывом. 
А хочется, чтобы активационная функция была непрерывная и дифференцируемая и нелинейная (зачем разберём дальше)



**сигмоидальный нейрон**
$$\large
f(x, \omega, b) = \sigma(\textbf{w} \cdot \textbf{x} + b)
$$
все то же самое плюс $\sigma$ - логистическая функция.
$$\large
\sigma(x) = \frac{1}{1+e^{-x}}
$$
Важно! Границы сигмоиды от 0 до 1

производная сигмоиды:
$$\large
\sigma(x)' = \sigma(x)-\sigma^2(x)
$$


![[sigmoid.png]]


**Гиперболический тангенс (tanh, th)**
$$\large
f(x, \omega, b) = \tanh(\textbf{w} \cdot \textbf{x} + b)
$$
tanh(t) - гиперболический тангенс t
$$\large
\tanh(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}
$$

![[tanh.png]]

Производная:
$$\large
\tanh(x)' = -\tanh^2(x)+1
$$


Занимательные свойства из задания:
1) $\large\sigma(-x) = 1 - \sigma(x)$ для любого $\large x$ 
2) $\large \tanh(-x) = -\tanh(x)$ для любого $\large x$ (гипер тангенс нечётен) 
3) $\large (\frac{d}{dx}\tanh)(0) > (\frac{d}{dx}\sigma)(0)$  производная tanh в точке 0 больше производной $\large \sigma$ в точке 0.

Так же из задания связь tanh с сигмоидой:
$$\large
\tanh(x) = 2\sigma(2x)-1
$$
 
**ReLU - Rectified linear unit**

$$\large
f(x, \omega, b) = \max(\textbf{w} \cdot \textbf{x} + b,\: 0)
$$

![[ReLU.png]]

**Softplus - аналитическое приближение ReLU **

$$\large
f(x, \omega, b) = \ln(1+ e^{\textbf{w} \cdot \textbf{x}}+b)
$$

$\ln(1+ e^{t})$ - softplus функция (по определению)

![[softplus.png]]

Производная softplus равна $\large \sigma(x)$

### Градиентный спуск

Квадратичная целевая функция:
$$
J = \frac{1}{2}\sum\limits_{i=1}^n(\hat{y}^{(i)}-y^{(i)})^2
$$
Это мера того, на сколько хорошо себя ведёт алгоритм

Это не совсем тоже самое что и функция потерь Loss.

Loss function - потери на одном конкретном примере, оно же cost function.
А квадратичная целевая функция комбинирует отдельные значения функции потерь в какое то одно число.


Функция потерь с одной стороны зависит от данных, с другой от параметров модели.
Данные - что то фиксированное
Параметры - то что мы меняем


так и запишем... "пощупать почву под ногами и понять, в какую сторону почва наклонена" (с)

Грубо говоря надо находить в точках направление скорейшего убывания целевой функции (лоса) 

Нам понадобится градиент и частная производная

**Градиент**


$$\large
\nabla J = 
\begin{bmatrix}
\frac{\partial J}{\partial w_1}\\
...\\
\frac{\partial J}{\partial w_m} \\
\end{bmatrix}
$$

Градиентом функции называется вектор составленный из частных производных этой функции по каждому их её аргументов.

Градиент задаёт направление наибыстрейшего роста функции.

Если мы сделаем шаг малой фиксированной длины $\large\varepsilon$, то наибольшее увеличение функции после этого шага произойдёт, если мы шагнём в направлении градиента (считаем что градиент не равен нулю).

Или, чуть более формально, для любой функции $J(x_1,…,x_d)$  среди всех 
$Δx=(Δx_1​,…,Δx_d​)$ таких, что $∥Δx∥=ε$ наибольшее значение выражению $J(x+Δx)−J(x)$  доставит $Δx=∇J(x)⋅ \frac{ε}{∥∇J∥}$ (то есть $Δx$ , совпадающее с $∇J(x)$ по направлению и имеющее длину $ε$ )

На всякий случай: $∥x∥$ — это длина вектора $x$ (корень из суммы квадратов его координат).

Так как нам надо минимизировать значение то нужно выбирать направление градиента со знаком минус

**Алгоритм обучения:**

1) Вычисляем значение градиента в определённой точке и умножаем его на -1
2) умножаем всё это на некую константу $\large \alpha$ - скорость обучения (lerning rate)
3) прибавляем всё это к текущему вектору весов.

![[algo1.png]]

4) Повторяем пока не надоест, либо пока веса не перестают меняться.


Разберёмся как получить градиент в случаях:
1) Целевая функция квадратичная и мы решаем задачу регрессии (линейный нейрон)
2) Целевая функция квадратичная и задача классификации (сигмоидальный нейрон)

Квадратичная функция потерь:
$$
J = \frac{1}{2}\sum\limits_{i=1}^n(\hat{y}^{(i)}-y^{(i)})^2
$$

$\hat{y}^{(i)} = w^{T}x^{(i)}$ - Линейный нейрон с учетом того, что в векторе w уже есть смещение bias.
![[нейрон.png]]

Тут и далее $x_i$ - это i-тая колонка. то есть колонка - одно наблюдение

Хотим найти градиент функции J по её параметрам.

Найдем сначала хотя бы один аргумент:
$$\large
\nabla J = 
\begin{bmatrix}
... \\
\frac{\partial J}{\partial w_j}\\
...\\
\end{bmatrix}
$$
Это какой то элемент вектора w с номером j

Подставим J в формулу $\large\frac{\partial J}{\partial w_j}$:

$$\large
\frac{\partial J}{\partial w_{j}}= 
\frac{\partial \frac{1}{2}\sum\limits_{i=1}^n(\hat{y}^{(i)}-y^{(i)})^2}
{\partial w_j}
$$

Несмотря на то что тут производная сложной функции, некоторые правила остаются верны
Производная суммы так и остаётся суммой производных

$$\large
= 
\frac{\sum\limits_{i=1}^n\partial \frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2}
{\partial w_j}=
$$
Объяснение: если мы хотим узнать как изменение нашего параметра повлияет на сумму ошибок по всем примерам, то вместо этого посмотрим как изменение параметров влияет на ошибку на конкретном примере, а потом просуммируем их.

Дальше применяем правило дифференцирования сложной функции к нашему примеру
все что относится к данным - константа $y^{(i)}$, всё что относится к параметрам - переменная $\hat{y}^{(i)}$
$$\large
= 
\frac{\sum\limits_{i=1}^n\partial \frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2}
{\partial w_j}=
$$
Пока забудем про сумму(главное не забыть её потом дописать):
$$\large
\frac{\partial \frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2}
{\partial \hat{y}^{(i)}} \cdot 
\frac{\partial \hat{y}^{(i)}}{\partial w_{j}} 
$$
Отсюда:
$$\large
 
\frac{\partial \frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2}
{\partial \hat{y}^{(i)}} = 
\frac{1}{2}\cdot 2(\hat{y}^{(i)}-y^{(i)}) \cdot 1
$$
Вторая часть: 
перепишем по определению что такое  $\hat{y}^{(i)}$ 
 $\hat{y}^{(i)} = w^{T}\cdot x^{(i)}$  
$$\large
\frac{\partial \hat{y}^{(i)}}{\partial w_{j}}=
\frac{\partial w_1\cdot x^{(i)}_1+w_2\cdot x^{(i)}_2+...+w_j\cdot x^{(i)}_j+...}{\partial w_j }
$$
ну и тут очевидно что все кроме j_ого элемента под номером i занулится.

$$\large
=\frac{\partial w_j\cdot x^{(i)}_j}{\partial w_{j}}=
x_j^{(i)}
$$

Тогда всё выражение переписывается в следующем виде
$$\large
\frac{\partial \frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2}
{\partial \hat{y}^{(i)}} \cdot 
\frac{\partial \hat{y}^{(i)}}{\partial w_{j}} =

 (\hat{y}^{(i)}-y^{(i)}) \cdot x_j^{(i)}
$$
В этом выражении можем узнать правило обучения перцептрона, которое мы использовали раньше.

Подставляем и получаем следующее:

$$\large

\frac{\sum\limits_{i=1}^n\partial \frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2}
{\partial w_j}=
\sum\limits_{i=1}^{n} (\hat{y}^{(i)}-y^{(i)}) \cdot x_j^{(i)}
$$

Таким образом получили формулу для расчета градиента

$$\large
\nabla J = 
\sum\limits_{i=1}^n
\begin{bmatrix}
... \\
(\hat{y}^{(i)}-y^{(i)}) \cdot x_j^{(i)}\\
(\hat{y}^{(i)}-y^{(i)}) \cdot x_{j+1}^{(i)}\\
...\\
\end{bmatrix}
$$
Знак суммы можем вынести за знак вектора

Исправим еще одно недоразумение:
Целевая функция J это суммарная ошибка по всем примерам которая есть в нашем наборе данных. это означает что мы не можем нормально сравнить ошибку на одном примере с общей ошибкой. для этого возьмем среднюю ошибку : 
$$
J = \frac{1}{n}\frac{1}{2}\sum\limits_{i=1}^n(\hat{y}^{(i)}-y^{(i)})^2
$$
Это не внесёт никакие доп.  сложности в расчет и множитель просто протащится 
$$\large
\nabla J = 
\frac{1}{n}
\sum\limits_{i=1}^n
\begin{bmatrix}
... \\
(\hat{y}^{(i)}-y^{(i)}) \cdot x_j^{(i)}\\
(\hat{y}^{(i)}-y^{(i)}) \cdot x_{j+1}^{(i)}\\
...\\
\end{bmatrix}
$$
Теперь из за этого мы можем сравнивать ошибку на одном примере с общей ошибкой и можем выщитывать градиент не по всему набору данных, а только по его части.
Это нужно для того что бы всё происходило быстрее, потому что по нашей формуле что бы сделать один шаг алгоритма нам нужно посмотреть на все наши примеры и совершить расчеты. это может работать очень долго. а так можно считать батчами по небольшой выборке
Такой подход называется стохастический градиентный спуск или (mini batch)

Сейчас мы решили задачу регрессии используя линейный нейрон и квадратичную целевую функцию.


**Теперь решим вопрос классификации**

Остаётся та же самая функция ошибки:
$$
J = \frac{1}{2}\sum\limits_{i=1}^n(\hat{y}^{(i)}-y^{(i)})^2
$$
И сигмоидальный (логистический) нейрон:

$$\large
f(x, \omega, b) = \sigma(\textbf{w} \cdot \textbf{x} + b)
$$
$$\large
\sigma(x) = \frac{1}{1+e^{-x}}
$$
Допустим хотим отличать мужчин от женщин
Закодируем $y^{(i)}$ = 1 - мужчины, а $y^{(i)}$ = 0 - женщины

Теперь 
$$\large
\hat{y}^{(i)} = \sigma(w^{T} \cdot x^{(i)})
$$

Нужно заново пересчитывать наши производные:

Снова применяем правило цепи. Кстати вот оно:

$$\large
\frac{\partial J^{(i)}}{\partial w_{j}}=
\frac{\partial J^{(i)}}{\partial \hat{y}^{(i)}} \cdot
\frac{\partial \hat{y}^{(i)}}{\partial w_{j}}
$$
Левый множитель не поменялся, правый изменился так:

$\large\hat{y}^{(i)} = \sigma(w^{T} \cdot x^{(i)})$ - добавилась сигма. Разделим выражение на две части - сумматорная функция $\large w^{T} \cdot x^{(i)}$   и значение активационной функции $\large\sigma(w^{T} \cdot x^{(i)})$

Тогда сигма раскрывается вот так:
$$\large
\frac{\partial J^{(i)}}{\partial w_{j}}=
\frac{\partial J^{(i)}}{\partial \hat{y}^{(i)}} \cdot
\frac{\partial \hat{y}^{(i)}}{\partial S} \cdot
\frac{\partial S}{\partial w_{j}}
$$
S - в данном случае - сумматорная функция $\large w^{T} \cdot x^{(i)}$

Первый множитель так и не поменялся, он у нас уже посчитан:
$$\large
 (\hat{y}^{(i)}-y^{(i)}) 
$$
Где $\large\hat{y}$ теперь равен $\sigma(w^{T} \cdot x^{(i)})$ 

Второй сомножитель:
$$\large
\frac{\partial \hat{y}^{(i)}}{\partial S} =
\frac{\partial\sigma(w^{T}\cdot x^{(i)})}
{\partial w^{T}\cdot x^{(i)}}

$$
и если заменить произведение на просто x то получаем ничто иное как просто производную сигмоиды (которую считали в начале курса) вот кстати она:
$$\large
\sigma(x)' = \sigma(x)-\sigma^2(x)
$$

Третий сомножитель:

Заметим что сейчас S это то чему раньше(в случае не классификации а регрессии) был равен $\large\hat{y}$ , и соответственно эта производная равна той, что была во втором сомножителе регрессии то есть просто:
$$\large
x_j^{(i)}
$$
Собирая всё в кучу получаем:

$$\large
\frac{\partial J^{(i)}}{\partial w_{j}}=
(\sigma(w^{T} \cdot x^{(i)})-y^{(i)})  \cdot
(\sigma(w^{T} \cdot x^{(i)})-\sigma^2(w^{T} \cdot x^{(i)}))\cdot
x_j^{(i)}
$$

Итого получаем такой алгоритм:

1) Случайным образом выбираем часть примеров из всех имеющихся
2) Считаем $\large\hat{y}$ для каждого из них
3) Вычисляем градиент целевой функции по весам для каждого из них
4) Суммируем то, что получилось
5) Обновляем веса
6) Проверяем критерии остановки алгоритма. Если хотя бы один из них отработал - выходим из цикла (последний пункт)

Далее идёт ДЗ в ноутбуке вот локальная ссылка на него 
![[Hw_1_student_version.ipynb]]
И вот репа на гитхабе где он лежит:
https://github.com/stacymiller/stepic_neural_networks_public


## Алгоритм обратного распространения ошибки

### Многослойный перцептрон

![[Pasted image 20220124053722.png]]
На вход приходит i - тый пример:
$$\large
x^{(i)} = 
\begin{bmatrix}
x^{(i)}_{1} \\
x^{(i)}_{2} \\
... \\
x^{(i)}_{m} \\
\end{bmatrix}
$$

Самый левый слой - входной, нейроны в нем не совсем нейроны, а просто наши входа, которые передают его дальше.
То что они выдали, помножится на соответствующие веса, и попадёт в следующие нейроны.

Первые нормальные нейроны (которые мы изучали ранее) - это нейроны скрытого слоя.

Все нейроны первого скрытого слоя - делять входы (то есть они общие и одинаковые)

Если скрытых слоев 2 и больше, то это уже глубокое обучение (DL)

Нейроны 1ого скрытого слоя работают привычно, их можно разделить так же на сумматорную и активационную функции

Результат сумматорной функции назовем **z**, а активационной **a**.

**a** на выходе домножается на веса связывающие этот нейрон, с нейронами следующего слоя, и всё повторяется, пока дело не дойдёт до выходного нейрона. 

На выходном нейроне всё так же, есть какое то **z** и **a**

Этот процесс называется **forward propogation** (по сути активация сети)
![[Pasted image 20220125061556.png]]


Первое что замечаем, это то, что все входные активации называются **z** также как и активации **а** и веса **w**, это неудобно, так как они вообще то могут быть разными.


$\large w^l_{jk}$ - обозначает вес, который соединяет нейрон с номером **j**(в который входит вес) из слоя с номером **l** c нейроном с номером **k** из слоя **(l -1)** 

$\large z^l_j$ - результат сумматорной функции нейрона с номером **j** из слоя **l**

$a^l_j$ = аналогично.

Смещение так же приписывается первым значением.
Так же смещения надо приписывать и к следующим слоям ( просто припишем в кадждый слой по нейрону из которого всегда выходит 1)

Другой вариант - смещения как бы сидят внутри нейронов(этим вариантом и будем пользоваться)

$\large b^l$ - вектор смещения всех нейронов в слое с номером $l$

$\large W^l$ - матрица весов входящих в нейроны слоя номер $l$

Как выглядит эта матрица(на примере  матрицы весов слоя между 2 и 3)

нейронов в слое в который входят веса 3, сообветственно строк будет 3
а столбцов 4

$$\large
W^{l}= 
\begin{bmatrix}
w^{3}_{11} \ w^{3}_{12} \ w^{3}_{13} \ w^{3}_{14} \\
w^{3}_{21} \ w^{3}_{22} \ w^{3}_{23} \ w^{3}_{24} \\
w^{3}_{31} \ w^{3}_{32} \ w^{3}_{33} \ w^{3}_{34} \\

\end{bmatrix}
$$

Любой ряд - веса которые входят в нейрон 3тьего слоя с соответствующим номером.

2ой вариант наоборот проинтерпретировать не ряд, а колонку
Каждая колонка это веса выхода из первого нейрона, предыдущего слоя

![[Pasted image 20220125162416.png]]


Возьмём j-й нейрон из l-го слоя. Пусть это будет сигмоидальный нейрон. Выберите, чему будет равна его активация.

$$\large
a^{l}_{j}= \sigma \left ( \sum\limits_{k}w^{l}_{jk} a^{l-1}_{k} + b^{l}_{j}\right )
$$

Теперь осталось разобраться с выходным слоем:

Нужно заметить, что на выходе мы просто берём активацию которая у нас получилась и используем её. 

Например, если в выходном слое мы используем такой нейрон, как гиперболический тангенс, а хотим предсказывать какую то вещественную переменную, то надо удостовериться, что тот разброс, который выдаёт активационная функция, совпадает с разбросом значений целевой переменной. Например, если мы предсказываем что то в диапазоне от -100 до 100 и просто используем гиперболический тангенс, то как бы наша сетка не старалась, она не может выдать значения больше чем диапазон -1 до 1.

Вообще нас никто не ограничивает выбирать разные активационные функции для разных слоев, несколько скрытых слоев могут иметь разные активационные функции иногда это даже очень полезно.

Чаще всего сталкиваемся с потребностью выбора активационной функции последнего выходного слоя нейронов.
Например в случае регрессионного анализа выбираем такие функции как  гиперболический тангенс (tanh) или линейный нейрон.

Для задачи классификации нам  подойдёт сигмоида или tanh

В случае бинарной классификации y принимают значения 1 и 0 и это хорошо работает с сигмоидальным нейроном и тогда вполне хорошо работает наша квадратичная ошибка где мы брали разницу  между получившейся сигмой и реальной меткой 1 или 0  и смотрели разницу $(...)^2$  
В случае же гиперболического тангенса нужно что то менять, так как он лежит в диапазоне от -1 до 1.

Исправляется это другим кодированием классов $y = {-1, 1}$ и всё будет работать нормально

**В случае когда несколько классов:**
например 3 класса:
$$\large
y^{(i)} = 
\begin{bmatrix}
0 \\
1\\
0 \\
\end{bmatrix}
$$
Это one hot encoding.

Добавляем к выходному слою еще 2 нейрона, и таким образом получаем на выходе вектор.
Выглядит он при прогонке каких то данных примерно так:
$$\large
\begin{bmatrix}
0.5 \\
0.3\\
0.1 \\
\end{bmatrix}
$$
И при принятии решения к какому классу относится объект, можем взять самый максимальный элемент.
При этом нам практически не нужно менять целевую функцию: 
Было так:
$$
J = \frac{1}{2}\sum\limits_{i=1}^n(\hat{y}^{(i)}-y^{(i)})^2
$$
А теперь просто поменяли разность классов (как бы лежащих на одной прямой) на разность векторов:
$$
J = \frac{1}{2}\sum\limits_{i=1}^n|\hat{y}^{(i)}-y^{(i)}|^2
$$
Сеть в таком случае выглядит так:
![[Pasted image 20220126020356.png]]


**Преимущества многослойного перцептрона:**

Преимущество многослойного перцептрона в том, что можно настраивать сильно нелинейные границы решения 

Так же известно, что нейронные сети - это универсальный апроксиматор. Сети с одним скрытым слоем, если в нем достаточно нейронов. мы можем приблизить любую функцию, с любой заданной заранее точностью

Добавляя новые слои, количество нейронов для аппроксимации сильно падает. 
![[Pasted image 20220126024935.png]]

Многослойный перцептрон ( он же перцептрон Румельхарта) учится за счет обратного распространения ошибки 

## Алгоритм обратного распространения ошибки 

Основная его идея - применить градиентный спуск для того что бы тренировать многослойный перцептрон.

Мы хотим найти частную производную целевой функции по каждому из параметров нейронной сети и методом градиентного спуска будем менять эти параметры так, что бы целевая функция уменьшалась.

Вопрос как найти все эти частные производные. 
![[Pasted image 20220126053709.png]]

Для унификации, не будем больше писать $\large \hat{y}_j$ а просто заменим его на $\large a^{L}_{j}$ 

**Введём определение**

**Ошибка** - ошибка у нейрона $\large j$ который лежит в слое $\large l$  будем обозначать буквой $\large \delta$  b определим её как частную производную нашей целевой функции, по значению сумматорной функции этого нейрона.
$$\large
\delta^{l}_{j} = \frac{dJ}{dz^{l}_{j}} 
$$
То есть если  значение ошибки в нейроне равно 0 то получается что частная производная целевой функции по сумматорной тоже равна нулю соответственно куда бы не толкать ошибку, лучше не станет, соответственно можно рассудить что нейрон находится в оптимальном положении.
Зная величину ошибки в нейроне, можно легко восстановить производную по весу, который входит в нейрон.
Разберёмся как связаны ошибки разных нейронов.

Сперва вычислим ошибки в выходных слоях, и потом посмотрим как эти ошибки перетекают в нейроны, которые связаны с этими выходными нейронами.
Таким образом суммарная ошибка как бы течёт и распространяется обратно.
Посмотрев на то как происходит этот процесс распространения ошибки мы легко сможем вычислить производные по всем весам. 

В одном из заданий мы вычисляли производную целевой функции по активационной функции   нейрона находящегося в выходном слое
В задании было так :

K - количество нейронов в выходном слое

j - номер нейрона в слое.

$\large y_j$ - j-тая компонента правильного ответа

$\large a^{L}_{j}$ - значение активационной функции
$$\large
J = \frac{1}{2} \sum\limits_{j=1}^{K}(a^{L}_{j} - y_{j})^{2} 

$$
$$\large
\frac{dJ}{da^{L}_{j}} = (a^{L}_{j} - y_{j})
$$

![[Pasted image 20220126055931.png]]

Теперь нужно вычислить ошибку нейрона, находящегося в выходном слое.

Я решал так:
$$\large
\frac{dJ(\sigma(x))}{dx} = 
\frac{dJ(\sigma(x))}{d\sigma(x)} \cdot
\frac{d\sigma(x)}{dx} 
$$
отсюда 
$$\large
\frac{dJ(\sigma(x))}{d\sigma(x)} = \frac{dJ}{da^{L}_{j}} = (a^{L}_{j} - y_{j})
$$
$$\large
\frac{d\sigma(x)}{dx} = \sigma(x) \cdot (1 - \sigma(x))
$$
И теперь в наших терминах:
$$\large
\delta^{L}_{j} = 
\frac{dJ}{dz^{L}_{j}} =
(\sigma(z_j) - y_j) \cdot \sigma(z_j) \cdot (1 - \sigma(z_j))
 
$$

В векторном виде вектор ошибок нейронов выходного слоя:

$\large \nabla_{a}J$ - градиент целевой функции по активациям выходного слоя.

$\large ⊙$ - **поэлементное** умножение векторов (всё как у суммы векторов, только вместо суммы — умножение)

$\large σ$ и $\large σ^{'}$ применяются к векторам поэлементно,

Все 3 варианта верны.
$$\large

\delta^{L} = \nabla_{a}J  \odot \sigma^{'}(z^{L})

$$
$$\large

\delta^{L} = \nabla_{a}J \odot \sigma(z^{L}) \odot
(1 - \sigma(z^{L})

$$
$$\large

\delta^{L} = (\sigma(z^{L})-y) \odot \sigma(z^{L}) \odot
(1 - \sigma(z^{L})

$$

Итак, мы нашли вектор ошибки для выходного слоя. 

Для остальных слоёв ошибка пока неизвестна. Нам надо каким то образом связать ошибку текущего слоя, с ошибкой в предыдущем.

Итак, мы знаем ошибку в слое $\large \delta^{l+1}$ и мы хотим узнать вектор  ошибок для слоя $\large \delta^{l}$  

Рассмотрим для начала один нейрон с номером j. Он связан соответствующими весами с нейроном следующего слоя. Соответственно, если мы немного увеличим значение его активационной функции $\large a^{l}_{j}$ то это изменение домноженое на веса, пойдёт в соответствующие нейроны следующего слоя. 
Например: 
было - $\large a^{l}_{j}$
стало - $\large a^{l}_{j}+ \Delta$ 

Мы можем легко узнать как изменится значение сумматорной функции у следующих нейронов. Она измениласть на $\large \Delta \cdot w_{1}$ и так далее (на каждом нейроне соответствующий вес умноженный на дельту) 

Вспомним свойство градиента: 
Изменение значения функции примерно равно градиенту, умноженному скалярно на приращение аргумента.
$$\large
\Delta J \approx \nabla J \cdot \Delta x 
$$
где  $\large J(x_{1},x_{2},x_{3})$   а $\large \Delta x$ вектор составленный их приращений различных координат.

Нашу функцию J можно записать как функцию от 3х аргументов, 
$$\large
J(z^{l+1}_{1},z^{l+1}_{2}, z^{l+1}_{3})
$$
![[Pasted image 20220127130539.png]]

Задачка: 

Как изменится **J**, если вектор изменения входных активаций слоя $l+1$ равен $(\Delta \cdot w^{l+1}_{1k}, \ldots, \Delta\cdot w^{l+1}_{n_{l+1}k})$  и $\Delta$ - маленькое

Под $n_l$ имеется в виду число нейронов на слое $l$.

Все верные ответы:

$\large ΔJ=Δ⋅(W^{l+1})_{k}^{T}​⋅δ^{l+1}$ где  $\large (W^{l+1})_{k}$ - это $k$-й столбец матрицы весов между $l$  и $l+1$ слоем

$\large ΔJ=Δ⋅(w_{1k}^{l+1},…,w_{n_{l+1}k}^{l+1})⋅∇_{z^{l+1}}J$ 

$\large ΔJ=Δ⋅(w_{1k}^{l+1},…,w_{n_{l+1}k}^{l+1}) \cdot \delta^{l+1}$ 


Как я понял ошибка на слое $\large l$ вычисляется как сумма ошибок слоя $l+1$ умноженная на соответствующие веса. 
![[Pasted image 20220128025951.png]]

Вот толковый видос на пальцах:
https://youtu.be/t-Jpm1axBko

Итак, мы знаем, как посчитать «назад» ошибку из $l+1$  слоя в $l$-й
Запрограммируем это пока помним как.

Напишите функцию, которая, используя:

набор ошибок $\large \delta^{l+1}$ для n примеров 
матрицу весов $\large W^{l+1}$  
набор значений сумматорной функции на $\large l$-м шаге для этих примеров

Возвращает значение ошибки $\large \delta^l$ на $l$-м слое сети.

- `deltas` — ndarray формы $\large (n,n_{l+1})$, содержащий в $i$-й строке значения ошибок для $i$-го примера из входных данных
- `sums`  — ndarray формы $\large (n, n_l)$   содержащий в $i$-й строке значения сумматорных функций нейронов $l$-го слоя для $i$-го примера из входных данных
- `weights` — ndarray формы $\large (n_{l+1}, n_l)$ содержащий веса для перехода между $l$-м и $(l+1)$ м слоем сети
- Требуется вернуть вектор $\large \delta^l$ — ndarray формы  $\large (n_{l}, 1)$  

Функции `sigmoid` и `sigmoid_prime` уже определены.

Обратите внимание, в предыдущей задаче мы работали только с одним примером, а сейчас вам на вход подаётся несколько. Не забудьте учесть этот факт и просуммировать всё, что нужно. И разделить тоже.

Подсказка
$$\large

J = \frac{1}{n}\sum\limits_{i=1}^{n}\frac{1}{2}|\hat{y}^{(i)}-y^{(i)}|^{2} ⟹ 
\frac{dJ}{d\theta} = 
\frac{1}{n}\sum\limits_{i=1}^{n} \frac{d}{d\theta}
(\frac{1}{2} |\hat{y}^{(i)}-y^{(i)}|^{2})

 
$$

 для любого параметра $\theta$, который не число примеров.

$\large n$ - количество примеров  
$\large n_{l}$ - количество нейронов в слое $\large l$   
$\large n_{l+1}$  - количество нейронов в слое $\large l+1$$ l+1


Формулу стянул отсюда:
http://neuralnetworksanddeeplearning.com/chap2.html#eqtnBP1

Пока не очень понял почему так:
$$\large
\delta^l =((w^{l+1})^{T} δ^{l+1})⊙ σ^′(z^l) 
$$

```python
import numpy as np
def get_error(deltas, sums, weights):
    """
    compute error on the previous layer of network
    deltas - ndarray of shape (n, n_{l+1})
    sums - ndarray of shape (n, n_l)
    weights - ndarray of shape (n_{l+1}, n_l)
    """
    # here goes your code
    errors = ((deltas.dot(weights)) * sigmoid_prime(sums)).mean(axis=0)
    return errors
```

Еще задачка:

$\large z^{l}_{j}=W^{l}_{j} \cdot a^{l-1} + b^{l}_{j}$ , где $\large W^{l}_{j}$ - ряд с номером j матрицы $\large W^{l}$ 

Тогда есть такое выражение:
$$\large
\frac{dJ}{dw^{l}_{jk}}=a^{l-1}_{k}\delta^{l}_{j}  
$$

**Теперь соберём всё в кучу:**

1. $\large \delta^{L}=\nabla_{a}J \odot \sigma'(z^{L})$ 
2. $\large \delta^{l}=((W^{l+1})^{T}\delta^{l+1}) \odot \sigma'(z^{l})$  
3. $\large \frac{dJ}{db^{l}_{j}} = \delta^{l}_{j}$ 
4. $\large \frac{dJ}{dW^{l}_{jk}}=a^{l-1}_{k}\cdot \delta^{l}_{j}$ 

1. Вектор ошибок выходного слоя, зная градиент целевой функции, по активациям нейронов  выходного слоя.
2. Зная вектор ошибок нейронов в каком то слое, вычислить вектор ошибок в предыдущем слое.
3. Как зная ошибки в слоях, вычислить производную по смещению
4. Вычислить производную по любому из весов.


Алгоритм такой:
1. Выбрать m примеров, на основании которых будет производиться изменение весов.
2. Осуществить прямое распространение активации для каждого примера не забывая при этом сохранять промежуточные активации для каждого слоя куда-нибудь, чтобы не пересчитывать их потом
3. Используем формулу (1) чтобы посчитать ошибки нейронов в выходном слое по каждому примеру.
4. Используем формулу (2) Теперь у нас есть ошибки нейронов во всех слоях, по каждому примеру
5. Используем формулу (3) и (4) не забываем просуммировать. Теперь у нас есть градиенты по параметрам и смещениям.
6. Обновляем параметры.
7. Проверяем критерии остановки алгоритма (последний пункт)


### Целевые функции

Требования целевой функции:
1) Должна быть дифференцируема
2) Зависела от выходов нашей сети 
3) Что бы производная этой функции по выходам сети выражалась как сумма производных этой функции по отдельным примерам 


**Идея регуляризации**

Мы решили, что мы не хотим больших весов. Для этого сообщим целевой функции, что большие веса - это плохо
Изначально у нас была целевая функция $\large J_{0}$ 

В новой целевой функции, помимо штрафа за неправильные ответы, введём еще штраф за веса
Новая целевая функция:
Для случая L2 регуляризации:
$$\large
J = J_{0} + \sum\limits_{l=1}^{L}\sum\limits_{j}\sum\limits_{k} (W^{l}_{jk})^2 
$$
Для L1 регуляризации:
$$\large
J = J_{0} + \sum\limits_{l=1}^{L}\sum\limits_{j}\sum\limits_{k} \left | W^{l}_{jk} \right | 
$$
--- 
**Разберёмся с начала с L2 регуляризацией**
Помимо прочего появляется еще один гиперпараметр $\large \lambda$ - насколько сильно штрафуем сеть за то, что она раздувает веса
$$\large
J_{L2} = J_{0} + \textcolor{red}{\lambda_2} \sum\limits_{l=1}^{L}\sum\limits_{j}\sum\limits_{k} (W^{l}_{jk})^2 
$$
Как изменится частная производная целевой функции по какому либо из параметров.
Пользуемся: производная суммы равна сумме производных.
Куча знаков суммы из производной тоже уходят, так как эти элементы не зависят от той, по которой дифференциируем
$$\large
\frac{dJ}{dw^{l}_{jk}} = \frac{dJ_0}{dw^{l}_{jk}} +
\lambda_2 \frac{d(w^{l}_{jk})^{2}}{dw^{l}_{jk}} =
$$
$$\large
= \frac{dJ_0}{dw^{l}_{jk}} + 
\textcolor{red}{2}\lambda_2 w^{l}_{jk}
$$
При этом 2ку можно просто убрать внутрь лямбды.

**Разберёмся с L1 регуляризацией**
$$\large
J_{L1} = J_{0} + \textcolor{red}{\lambda_1} \sum\limits_{l=1}^{L}\sum\limits_{j}\sum\limits_{k} \left | W^{l}_{jk} \right | 
$$
$$\large
\frac{dJ}{dw^{l}_{jk}} = \frac{dJ_0}{dw^{l}_{jk}} +
\lambda_2 \frac{d|w^{l}_{jk}|}{dw^{l}_{jk}} =
$$
Тут модуль не очень то дифференцируемая функция и в нуле мы это сделать не можем  , а во всех остальных местах можем. если $x > 0$ то производная 1, если   $x < 0$ то -1. то есть функции sign. Если 0 то нас этоустраивает и производную тоже делаем 0.
$$\large
= \frac{dJ_0}{dw^{l}_{jk}} + 
\textcolor{red}{2}\lambda_1 sign(w^{l}_{jk})
$$
Есть еще смешаное правило регуляризации Elastic net но автор его не показывает.

Давайте разберёмся какими свойствами обладают эти регуляризации

Ridge Regression = L2
Lasso Regression = L1

![[Pasted image 20220130021220.png]]

Тут показаны зависимости от того, насколько сильно мы штрафуем за увеличение весов  (число лямбда) (ось x) и тем, насколько большими получатся веса, после тренировки классификатора.
Считаем что чем больше значение на оси x тем меньше лямбда

Видим что в L1 параметры появляются с ростом x по одному, а в L2 из одной точки и потом расходятся в зависимости от того насколько они полезны.

То есть L1 может как бы "отбирать" признаки, но при этом плохо штрафует за большие веса.

Разберёмся почему так происходит. Посмотрим на графики

По оси x - размер веса, по оси y - стоимость штрафа при увеличении этого веса.

Видим, что у L1 штраф всегда меняется линейно, поэтому сетке выходно использовать всегда один и тот же вес, если он самый полезный в данной итерации,  (если у нас какой то признак лучше всех влияет на качество модели в данную итерацию, его и будет раздувать по максимуму, а только потом уже все остальные признаки)
В случае же с L2 регуляризацией видно, что в нуле изменения у всех весов почти бесплатные, за то потом начинают резко расти. 
поэтому сетке выгодно сначала увеличить ВСЕ веса около нулевой точки, а потом уже выбирать лучшие, при этом видно, что L2 на больших значениях уже начинает люто штрафовать веса.

![[Pasted image 20220130023643.png]]

В некотором смысле, целевая функция - это способ сказать нейронной сети, чего мы от неё хотим и как мы будем измерять её успешность.
Раньше мы спрашивали у классификатора, что бы он минимизировал квадрат отклонения между предсказанным и истинным значением целевой переменной. Если предсказанное значение это 0 или 1 то это не очень работает

Классическая для бинарной классификации функция потерь - кросс-энтропия
$\large y^{(i)}$ - правильный ответ на примере с номером i 
$\large a^{(i)}$ - активация нейрона в выходном слое. 
$$\large
J = -\frac{1}{n} \sum\limits_{i=1}^{n} 
\left [ y^{(i)}\ln a^{(i)} + (1-y^{(i)}) \ln (1-a^{(i)}) \right ], \ \ \ \ \
y^{(i)} \in {0, 1}
$$
Разберёмся на примере: 
Допустим у нас есть набор данных $\large x$  и соответстующие им $\large y$ - правильные ответы. 
Так же у нас есть $\large \hat{y}$ - вектор предсказаний нашей модели. который в данном случае состоит из вероятностей (для каждого примера, мы предсказали что его вероятность равна единице)

Мы хотим что бы наша сеть делала правдоподобные предсказания.

Что такое правдоподобность в бытовом смысле - это когда у нас есть какое то утверждение и реальность, если реальность не согласуется с утверждением мы говорим, что утверждение не правдоподобно.

Наши утверждения заключаются в том, что предсказала наша модель, например: взяли пример с номером 1, и получили ответ 0.7.  То есть модель утверждает, что для примера с номером 1, вероятность того что этот пример принадлежит к классу с номером 1 - 0.7. 
Взяли пример 2. Получили вероятность 0.3 итд.
Таким образом утверждения нашей модели заключается в наборе таких вероятностей для каждого примера.
Реальность же заключаетсяв правильных ответах для наших примеров, например: 1, 0, 1, ...
Теперь нам нужно каким то образом проверить, а согласуется ли предсказания с реальностью.
Сделаем это так: посчитаем вероятность получить правильные ответы(те что даны и равняются $\large y^{(i)}$), если правдой являются наши предсказания $\large \hat{y}$ .
Обязательное предположение (примеры генерируются независимо)
Эту вероятность можно посчитать как:
В первом примере получили 0.7 и правильный ответ 1, в таком случае и вероятность получить такой  ответ была **0.7**
Во втором случае правильный ответ 0, и сетка сказала, что вероятность того что там ответ 1 - 0.3. То есть он уверен что там 0 с вероятностью **0.7**
Вероятность получить такой ответ одновременно, это произведение этих вероятностей (при условии что события независимы)
так делаем для всех примеров и получаем на выходе какое то очень маленькое число (вне зависимости от того на сколько хорошая у нас модель)
Получим ситуацию когда чем ближе наши предсказания к реальности, тем большую оценку мы получаем на выходе. 
Это и есть функция правдоподобия( получили набор ответов и предсказаний на входе и на выходе одно число - оценка правдоподобия)
Запишем эту функцию правдоподобия:
$$\large
\prod\limits_{i=1}^{n}\hat{y^{(i)^{y^{(i)}}}}
(1-\hat{y^{(i)}})^{(1-y^{(i)})}
$$
Эта функция верна и в том же случае, если взять от неё логарифм, тогда уйдут произведения и всесто них будут суммы, и интервал станет не от 0 до 1 а от минус бесконечности до единицы. 

В случае если $\large y^{(i)}$ и  $\large a^{(i)}$  вктора (многоклассовая классификация) то модифицируем функцию как 

$$
J = -\frac{1}{n} \sum\limits_{i=1}^{n}  \sum\limits_{j=1}^{m}
\left [ y^{(i)}\ln a^{(i)} + (1-y^{(i)}) \ln (1-a^{(i)}) \right ], \ \ \ \ \
y^{(i)} = 
\begin{bmatrix}
y^{(i)}_{1} \\
... \\
y^{(i)}_{m}
\end{bmatrix}
$$
То есть просто добавили дополнительное суммирование.
Есть один неприятный момент: если мы просто используем сигмоидальные активационные функции для каждого из этих нейронов то вероятностная интерпретация уже не будет работать.
Пример:
вектор активаций для одного примера выгдялит так 
$[0.7, 0.1, 0.4]^{T}$ 0.7 для первого класса, 0.1 для второго и 0.4 для третьего.  и они вполне могут не суммироваться к единице.

Для получения более менее вероятностного распределение надо пользоваться **softmax** но он в этом курсе не рассматривается.

## Мониторинг состояния сети 
### Мониторинг состояния сети

