[[ML_на_графах]]

https://editor.codecogs.com/ 

## Лекция 1

Пререквизиты:
* Дискретная математика
* линейная алгебра
* Алгоритмы и структуры данных
* тервер
* дифференциирование
* питон

### Общие вопросы и понятия
Книги:

* ”Network Science”, Albert-Laszlo Barabasi, Cambridge University Press, 2016. http://networksciencebook.com
* ”Networks: An Introduction”. Mark Newman. Oxford University Press, 2010.
* ”Social Network Analysis. Methods and Applications”. Stanley Wasserman and Katherine Faust, Cambridge University Press, 1994
* ”Networks, Crowds, and Markets: Reasoning About a Highly Connected World”. David Easley and John Kleinberg, Cambridge University Press 2010.

Темы курса:

* Statistical properties and network modeling (Статистические свойства и сетевое моделирование)
* Network structure and dynamics (Структура и динамика сети)
* Predictions on networks (ML)(Прогнозы в сетях)
* Network embeddings
* Graph neural networks (Граф нейронных сетей)
* Knowledge graph retrieval and completion (Поиск и завершение графа знаний)

Следующий курс:

* Spark and BigData for relational Data
* Distributed ML on large graphs (Распределенное машинное обучение на больших графах)

Терминология:

* network = graph = сеть
* nodes = vertices, actors = вершины
* links = edges, relations = ребра
* clusters = communities = скопления связных точек

* Network is represented by a graph G(V, E), comprising a set of vertices V and a set of edges E, connecting those vertices.
* Graph can be represented by an adjacency matrix A, where Aij - availability of an edge between nodes i and j
* In an unweighted graph Aij is binary {0, 1}, in a weighted graph an edge can carry a weight, A- non-binary
* Undirected graph is a graph where edges have no orientation, edges are defined by unordered pairs of vertices, Aij = Aji
* Directed graph is a graph where edges have a direction associated with them, edges are defined by ordered pairs of vertices, $Aij\neq Aji$ $


* A path between nodes i and j is a sequence of edges connecting vertices, starting at i and ending at j, where every vertex in the sequence is distinct
* Distance between two vertices in a graph is the number of edges in a shortest path (graph geodesic) connecting them.
* The diameter of a network is the largest shortest paths (distance between any two nodes) in the network
* Average path length is bounded from above by the diameter; in some cases, it can be much shorter than the diameter


* A graph is connected when there is a path between every pair of vertices
* A connected component is a maximal connected subgraph of the graph. Each vertex belongs to exactly one connected component, as does each edge.
* A directed graph is called weakly connected if replacing all of its directed edges with undirected edges produces a connected (undirected) graph.
* A directed graph is strongly connected if it contains a directed path between every pair of vertices. A directed graph can be connected but not strongly connected.


* The degree of a vertex of a graph is the number of edges incident to the vertex
Степень вершины графа — это количество ребер, инцидентных
вершина

* A vertex with degree 0 is called an isolated vertex.
Вершина со степенью 0 называется изолированной вершиной

* In a directed graph the number of head ends adjacent to a vertex is called the in-degree of the vertex and the number of tail ends adjacent to a vertex is its out-degree
Если граф ориентированный, то возникает 2 вида степени -входящие и исходящие и они считаются по отдельности
Если в графе с n вершинами и m ребрами сложить все степени вершин, то сумма всех степеней - удвоенное число ребер

* A vertex with in-degree=0 is called a source vertex, with out-degree=0 is a sync vertex

Итого: 
* Сети не регулярные, но и не случайные
* Не тривиальная топология
* Масштабируемость сетей (scale-free networks)
* универсальные свойства которые можно изучать методами статистического анализа.
* везде
* Комплексные системы

### Свойства сетей


Реальные свойства сетей.
1) Закон распределения степеней вершин (power law node degree distribution)
Он говорит о том что на самом деле вершин с большой степенью крайне мало.
2) Маленький диаметр и среднее кратчайшее расстояние - эффект маленького мира.
3) Высокий коэффициент кластеризации (транзитивность)

**Закон распределения степеней вершин**

Если мы рассматриваем население города, и процент городов с таким населением,  то есть обратно пропорциональная зависимость. 

То есть городов милионников - мало, а городов в которых мало людей - много.

![[1 1.png]]

k - параметр по оси x

$$\large
f(k) = \frac{C}{k^γ} = Ck^{−γ}
$$
$$\large
log f (k) = log C_{−γ}log k
$$
Первое свойство реальных сетей - это то что они действительно удовлетворяют Закон распределения степеней вершин


Интересующее количество - частотное распределение степеней ноды
(Плотность имеет вид пропорциональный k в степени гамма)
гамма - коэффициент больше единицы который показывает скорость убывания частоты встречаемости каких то элементов.
$$\large
f(k) \sim \frac{1}{k^\gamma}
$$

Одно из свойств реальных сетей - высокий коэффициент кластеризации (~ 15%)


**Эффект маленького мира**

Эксперимент:
Как без интернета померять ближайшее кратчайшее расстояние в графе кто кого знает. 

Нужно доставить письмо до конкретного адресата, если ты его знаешь, то надо написать ему лично, если нет, то написать кому то письмо с просьбой повторить процедуру отправить оригинальное письмо на конечный адрес. 

В среднем количество дошедших писем 29% и средняя длина пути 5.2

Это закон о 6 рукопожатий. 

**Степень вершины и их распределение**

* У каждой вершины i есть степень $k_i$ . она может принимать значения (1, 2, 3, ... , $k_{max}$ ) (изолированные вершины выкинули из графа)
* $n_k$ - количество вершин которые имеют степень  k 
* общее количество вершин $\large N = \sum_kn_k$ 

$$\large
P(k_i=k)=P_k=\frac{n_k}{\sum_kn_k}=\frac{n_k}{N}
$$

Как математически получается **power law distribution**
* Power law распределение $\large k \in\mathbb{N}, \gamma \in \mathbb{R}> 0$ 
$$
P_{k} = Ck^{−γ} = \frac{C}{k^γ}
$$   
* Log-log координаты при этом: (уравнение для линейной регрессии)
$$\large
\log P_k =-\gamma \log k +\log C 
$$
* Нормализация
$$\large
\sum\limits_{k=1}^{\infty}P_{k}=
C\sum\limits_{k=1}^{\infty}k^{-\gamma} =
Cζ(\gamma)=1;\: 
C=\frac{1}{ζ(\gamma)}
$$
* Riemann zeta function (Дзета-функция Римана) $\large \gamma>1$ 
$$\large
P_{k}= \frac{k^{-\gamma}}{ζ(\gamma)}
$$
Можно сделать более просто и сказать что это распределение дискретное и апроксимируется непрерывной случайной величиной и тогда: 
![[2.png]]
![[3.png]]

* Как влияет размер сети на её хабы (вершины с большой степенью)

* Вероятность наблюдения одного узла со степенью $\large k>k_{\max}$:
$$\large
Pr(k\geq k_{\max})=\int_{k_{\max}}^{\infty}p(k)dk
$$
* Ожидаемое количество узлов со степенью $\large k\geq k_{\max}$:
$$\large
N\cdot Pr(k\geq k_\max)=1
$$
* Ожидаемая степень наибольшего узла в экспоненциальной сети $\large p(k)=Ce^{-\lambda k}$:
$$\large
k_\max=k_\min+\frac{\ln N}{\lambda}
$$
* Ожидаемая степень наибольшего узла в power law сети $\large p(k)= Ck^{-\gamma}$ 
$$\large
k_\max=k_{\min}N^\frac{1}{\gamma-1}
$$

**Scale free network** (что вообще можно сказать о доверительных интервалах)

![[4.png]]

Степень произвольно взятой вершины можно оценивать как среднюю степень. (сигма^2 среднеквадратичное отклонение)
$$\large
k= \left<k\right>\pm \sigma_{k}, \ \ \sigma_{k}^{2}=\left<k^{2}\right> - \left<k\right>^2
$$
![[5.png]]

Закон 6 рукопожатий не всегда будет равняться 6, но всё равно это будет константная величина сильно меньше размера сети

PDF (probabikity dansyty function) - функция плотности
CDF - функция распределения. 
![[6.png]]

$x_\min$  - начиная с этой степени распределение удовлетворяет закону пуаро.
![[7.png]]
![[8.png]]

Тест колмагорова-смирнова - самая простая функция сравнения двух распределений

Есть эмпирическая функция распределений (лесенка на левом графике)
Её нужно апроксимировать некоторой параметризованой кривой
У этой кривой есть два параметра $\gamma$ и x_min, при этом камму можно выразить через  x_min с помощью оценки максимального правдоподобия.
Что бы теоретическая функция была максимально близка к эмпирической, берём максимум разности между этими функциями
То есть по сути находится максимальное расстояние между функциями по всем x

Строим 2ой график зависимости D от x_min и находим нужную точку

![[9.png]]


### Семинар
У нас есть для каждой вершины список кратчайших путей до всех остальных вершин. 
Для каждой вершины мы находим максимальный путь среди всех.
Теперь для каждой вершины у нас по одному максимальному значению
И вот максимальное среди этих максимальных - диаметр, а минимальный - радиус
-   `nx.radius` - радиус графа. 
-   `nx.diameter` - диаметр графа 
-   `nx.average_shortest_path_length` - среднее кратчайшее расстояние

* Коэффициент кластеризации - определяется для каждой вершины отдельно, т.е для каждой вершины есть какое то количество соседей, между соседей может быть ребро, а может и не быть. если между всеми соседями есть ребро, то коэф. кластеризации максимальный, если нет ни одного ребра - то минимальный. считается так: 
$$
\frac{колличество\_ребер\_между\_соседями}{максимально\_возможное\_количество\_ребер}
$$
 `nx.average_clustering` - средний коэффициент кластеризации по графу
































































