[[base_dl]]



# Лекция 5
Данные и метрики. Batchnorm. Pytorch Lightning. Optuna.



На этой лекции рассматриваются:

* Формулировка и сбор данных
* Выбор метрик



## Данные Train/dev/test

Train set и Validation set из одного распределения

* **Bias** модели - величина ошибки на **Train**
* **Variance** модели - разница ошибок **Validation** и **Train**

![[Pasted image 20220223205916.png]]
Описывают соответствие модели и данных

Посмотрим в другом срезе:

Увеличение размера тренировочных данных.

Нижний график растёт, так как тренировочных данных становится больше и модели труднее их обобщить, в то же время модель начинает лучше обобщать и ошибка на тесте падает

![[Pasted image 20220223210238.png]]

Задаёмся вопросами:
* какие датасеты и какого размера нам нужны
* Из какого распределения

Самый простой подход применяемый при обучении - разделение данных на тренировочный и тестовые.

![[Pasted image 20220223211539.png]]

Отбираем модели по Test метрикам => переобучаемся под Test

Хочется оценить степень переобучения.

Решение: Dev корпус

![[Pasted image 20220223211834.png]]


Часто трейн бывает с искусственно созданными/намайненые на стороне данные. поэтому имеет смысл смешать их и еще одним датасетом, отщипнутым от трейн Train-dev.
И тогда, если на этом датасете всё ок, а на test всё плохо, то дело в намайненых данных.

Хотим улучшить качество модели за счет данных
*  Собрать новых данных? 
*  Почистить имеющиеся?

* Шумных данных нужно больше 
*  Количество может компенсировать качество

![[Pasted image 20220224045834.png]]


* Dataset size is not all you need
* Распределение данных важно
* Quality / dataset size trade-off
* Переобучаемся не только под train, но и под dev (и даже под test)
*  Dev и Test стоит иногда менять
* Если train и dev из разных источников, можно выделить train-dev


### Размер test set

Какого размера нужен test 10 1000 10000?

Есть такая модель 
![[Pasted image 20220225214751.png]]

$\large Y^{*}$  - правильный ответ.

$$\large
Error = 
\left\{\begin{matrix}
0, Y = Y^{*}
\\
1, Y \neq Y^{*}
\end{matrix}\right.
$$
Error - случайная величина бернулли(p)
p -  вероятность ошибки модели

N0 - число правильных классификаций
N1 - число ошибок 

Размер Test: N = N1 + N0

$\large P(p=x| N_{0}, N_{1})?$ 

оценить можно по теореме байеса:
$$\large
P(p=x| N_{0}, N_{1}) = 
\frac{P(N_{0},N_{1}|p=x)P(p=x)}
{\int\limits_{y}P(N_{0},N_{1}|p=y)P(p=y)dy}
$$ $\large P(p=x):Uniform(0,1)$ - считаем априорное распределение равномерным.

$\large P(N_{0},N_{1}|p=x) = x^{N_{1}}(1-x)^{N_{0}},x \in [0,1]$ 

$$\large
P(p=x| N_{0}, N_{1}) = 
Beta(N_{1}+1,N_{0}+1) =
\frac{x^{N_{1}}(1-x)^{N_{0}}}
{B(N_{1}+1, N_{0}+1)}
$$

![[Pasted image 20220226015032.png]]


**Доверительный интервал**
Доверительный интервал с уровнем доверия alpha = 0.95?
$$\large
PPF_{p}(\alpha)=x: P(p \leq x) = \alpha
$$
$$\large
\Delta = PPF(\alpha+\frac{1-\alpha}{2})-PPF(\frac{1-\alpha}{2})
$$

![[Pasted image 20220226030121.png]]

Чем точнее у нас алгоритм, тем больше мы хотим видеть количество нулей( сначала алгоритм улучшается процентами, потом уже на капе идут доли процентов) и тем больше нужна тестовая выборка.


### Метрики

Технические
* оценивают подсистемы
* выявляют возможности для улучшений
Продуктовые
* связаны с бизнесом
* оценивают систему целиком
* одно число
Метрики из статей и стандартов
* сравнение с конкурентами


Пример: трекинг людей

Технические метрики
![[Pasted image 20220226184713.png]]


Продуктовые метрики
Задача:
* у заказчика есть база сотрудников с фото
* нужно найти посторонних людей на видео с камеры

Какое число выбрать в качестве продуктовой метрики?

Какие параметры важны:
* скорость работы пайплайна (ms / frame)
* частота ложных срабатываний (1 / hour)
* вероятность правильной классификации постороннего

Как сделать одно число?

**Вариант 1: усреднение**

1. Можно связать частоту ложных срабатываний с вероятностью правильной классификации сотрудника
2. Вероятности правильной классификации сотрудника и постороннего можно усреднить (mean, harmonic mean)

Как быть с быстродействием?

**Вариант 2: ограничение**

Какие параметры важны:
* скорость работы пайплайна (ms / frame)
* частота ложных срабатываний (1 / hour)
* вероятность правильной классификации постороннего

1. Ложные срабатывания допустимы не чаще 1 / час (в среднем)
2. Нужно обрабатывать кадр быстрее 200ms на CPU

=> остается один свободный параметр - вероятность обнаружения постороннего



## Batch normalization

Применяется в основном в свёрточных и полносвязных сетях.

Проблемма:
Есть какая то сеть(довольно глубокая) по мере сигнала прохождения появляются какие то признаки, которые как то распределены
Мы сделали шаг оптимизации, обновили параметры и слои у нас поменялись.
Слой 1 изменился и изменилось распределение данных, которое поступает на 2ой слой.
Как 2ому слою успевать адаптироваться к постоянно меняющимся входным данным
Эта проблема называется Internal covariate shift
(Смещение распределений между слоями и зависимость каждого следующего слоя, от распределения весов в предыдущем слое)

Вопрос:
Как эту зависимость уменьшить, что бы каждый слой учился вне зависимости от предыдущих и за счет этого ускорить обучение.

![[Pasted image 20220226185200.png]]

Нормировка:

Выходы из предыдущего слоя можно попробовать нормализовать, что бы в следующий слой они поступали в нормализованном виде


![[Pasted image 20220226185556.png]]


Суть в том, что бы нормализовать данные  используя статистику по тем элементам которые содержатся в батче данных на текущей операции. (если обучаем модель с батчем 256, то у нас 256 примеров для оасчета нормировочной статистики)



Во время тренировки:

* Вычесть среднее по батчу
* Разделить на STD батча
* Умножить на обучаемый scale
* Добавить обучаемый bias

![[Pasted image 20220226185743.png]]


Следствия:
* Поведение зависит от данных батча
* Поведение зависит от размера батча

То есть если в батч попали только данные из одного класса, то статистики будет смещены, и это очень нехорошо.
То есть данные нужно хорошо шафлить.


Что делать в inference(режиме работы а не тренировки) если нет батча?
(хотим сделать предсказания по одному примеру)

Тогда используются  средние и STD усредненные по traininig set для нормализации на тестовых данных

Пример:
![[Pasted image 20220226210536.png]]

Так сходится быстрее и можно учится с большими лёрнинг рейтами 
![[Pasted image 20220226210556.png]]

Зачем так сложно:
* Если использовать скользящие средние в train, обучение может взорваться
* Появляется разница между train и test
* Иногда это благо, т.к. вносит регуляризацию

А вставлять до или после активации?:
![[Pasted image 20220226210813.png]]

В результате оказывается что всё равно, но в проде А можно будет оптимизировать и склеить это в 1 преобразование, это приведёт к ускорению inference.


**Batchnorm summary

* BN ускоряет обучение CNN и FC сетей
* BN позволяет использовать больший Learning Rate
* BN вносит разницу между train и test
* При больших batch size разница меньше, а статистики устойчивие






## Семинар 5: PyTorch Lightning и подбор гиперпараметров


-   Обучение моделей при помощи PyTorch Lightning
-   Подбор гиперпараметров при помощи Optuna

Пакеты в практике:
-   opencv-python
-   torch
-   torchvision
-   pytorch_lightning
-   optuna


Типичный ML pipeline.

Большое количество кода повторяется от проекта к проекту:

-   Тренировочный цикл
-   Управление чекпоинтами
-   Работа с GPU и распределённая тренировка

Типичные пайплайны уже реализованы в высокоуровневых библиотеках:

-   TensorFlow Estimator
-   PyTorch Ignite
-   PyTorch Lightning
-   Catalyst

Получается меняется наследование с nn.module на LightningModule

![[Pasted image 20220227035458.png]]


train loader
было
![[Pasted image 20220227052314.png]]

стало
![[Pasted image 20220227052335.png]]

train

было
![[Pasted image 20220227053351.png]]


стало
![[Pasted image 20220227053430.png]]

Цель - снизить повторяемость кода

Если мы реализуем эти классы, то мы сможем запустить обучение с помощью pytorch lightning. Это позволит сделать трейнинг луп из коробки, сохраняет чекпоинты модели, распределять модель на несколько гпу.

## Тренировка с Pytorch Lightning

Создадим три базовых класса: LightningDataModule, LightningModule, Trainer.


**LightningDataModule

-   Хранит информацию о Train/Dev/Test корпусах
-   Создаёт DataLoader-ы


Если нужно несколько корупсов:
[https://pytorch-lightning.readthedocs.io/en/stable/multiple_loaders.html](https://pytorch-lightning.readthedocs.io/en/stable/multiple_loaders.html)



**LightningModule

Объединяет:
-   Модель
-   Loss
-   Оптимизатор
































































