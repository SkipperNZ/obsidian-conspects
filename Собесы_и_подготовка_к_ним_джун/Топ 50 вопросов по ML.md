
```toc
```



## SQL запросы /подзапросы

### SQL  (Необходимо вывести список сотрудников, получающих заработную плату большую, чем у непосредственного руководителя. )

![[Pasted image 20220602141126.png]]


### SQL GROUP BY (Найти список ID Отделов с максимальной суммарной зарплатой сотрудников)
![[Pasted image 20220602141433.png]]


### SQL /MAX() + подзапрос (Выберете самое большое значение заработной платы, не равное максимальной заработной плате, полученной по всей таблице)
![[Pasted image 20220602142133.png]]


### SQL/ ROW_NUMBER() (Пронумеруйте строки в таблице employee)
![[Pasted image 20220602142402.png]]

### SQL / PARTITION BY (Пронумеруйте строки в таблице в разрезе департамента по зарплате)
![[Pasted image 20220602142545.png]]

## Статистические параметры

### Что такое средние?
Средним для группы чисел называется любое число заключенное между наименьшим и наибольшим из них

**Среднее арифметическое** - разновидность среднего значения. Определяется как число, равное сумме всех чисел множества, делённое на их количество

### Матожидание
Это разновидность среднего значения, означающее среднее значение случайной величины
![[Pasted image 20220602143229.png]]

### Медиана 
Это квантиль, порядка 0.5 
То есть такое число, которое находится посередине, когда мы расписываем наши числа в порядке возрастания. 
![[Pasted image 20220602145458.png]]

### Квантиль
Значение, которое заданная случайная величина не превышает с фиксированной вероятностью. 
Например, 0.25 квантиль - число, ниже которого лежит примерно 25% выборки. 

### Мода
Самое вероятное значение случайной величины (в нестрогом смысле)
![[Pasted image 20220602161243.png]]

### Как располагаются средние на бимодальном распределении. 
![[Pasted image 20220602161410.png]]


### Дисперсия 
Мера разброса значений случайной величины относительно её математического ожидания.
$$\large
DX=E(X-EX)
$$

### Среднеквадратическое отклонение СКО 
это корень из дисперсии.
Используется для оценки масштаба возможного отклонения случайной величины от её математического ожидания. 


### Интерквантильный размах
$$\large
IQR = X_{0.75} - X_{0.25}
$$
В данном случае по формуле мы имеем разность квантилей порядка 0.25 и 0.75


## Теория вероятностей

### Свойства вероятности
![[Pasted image 20220602162246.png]]



### Условная вероятность
![[Pasted image 20220602162452.png]]


### Формула полной вероятности
![[Pasted image 20220602162550.png]]

### Теорема Байеса
![[Pasted image 20220602162800.png]]

### Биноминальное распределение и распределение Пуассона


## Метрики качества в задачах регрессии

### Среднеквадратичная ошибка  MSE
![[Pasted image 20220602163036.png]]


### Средняя абсолютная ошибка MAE
![[Pasted image 20220602163231.png]]


## Метрики качества в задачах классификации

### Accuracy
Доля правильных ответов. 
Хорошо применима если классы сбалансированы. 


### Precision точность
![[Pasted image 20220602163459.png]]

### Recall - полнота
![[Pasted image 20220602163744.png]]
![[Pasted image 20220602164014.png]]

### Арифметическое среднне precision и recall - F мера
![[Pasted image 20220602164519.png]]


### Logloss (Логарифмическая функция потерь)
Применяется на задачах классификации и её выводят из функции правдоподобия. 
Берём функцию правдоподобия и берём от неё логарифм.
Очень сильно штрафует за неправильные ответы.
![[Pasted image 20220602170104.png]]

### Lift
Метрика прироста концентрации.
Когда интересует точность не по всей выборке,  а точность по 5% или по 10%
Применимо при исследовании подмножества.
![[Pasted image 20220603015848.png]]

### ROC-AUC
Метрика оценки принадлежности класса.
![[Pasted image 20220603021343.png]]


### Gini
Часто используется в задачах кредитного скоринга.

![[Pasted image 20220603021752.png]]



### PR кривая
Предположим что наш положительный класс намного меньше по размерам и ROC-AUC даст неадекватную оценку. И можно применить метрику Precision-Recall 

![[Pasted image 20220603025953.png]]


### Разница между задачами классификации и регрессии
Классификация соотносим объект какому то классу
Регрессия - предсказываем значение какое то непрерывное значение
Алгоритмы регрессии можем применять в классификации, по типу логистической регрессии


### Алгоритмы регрессии и классификации
![[Pasted image 20220603030520.png]]


###  Линейные модели 
![[Pasted image 20220603031013.png]]


### Нелинейные алгоритмы классификации и регрессии
Случайные леса, xgboost .... 


### Логистическая регрессия
![[Pasted image 20220603031312.png]]


### Подбор параметров логистической регрессии


![[Pasted image 20220603031505.png]]
![[Pasted image 20220603031830.png]]

### Регуляризация 
![[Pasted image 20220603031624.png]]


### Решающие деревья
![[Pasted image 20220603032037.png]]

### Критерий информативности (Gini, Entropy)

![[Pasted image 20220603032241.png]]

### Xgboost Градиентный бустинг
Строится на основании базовых деревьев.
Тут мы используем ошибку от предыдущего дерева и на основании этой ошибки строим текущее базовое дерево.
![[Pasted image 20220603032620.png]]

### Xgboost 
![[Pasted image 20220603033004.png]]

### Градиентный бустинг и решающие деревья
Чем они отличаются. 
Решающее дерево мы строим сверху вниз (от вершины к листьям разбиваем с учетом информативности)
При градиентном бустинге строим немного по горизонтали (берем предыдущее дерево и на основании его строим новое)


### Random forest
![[Pasted image 20220603033351.png]]

### Про bagging в random forest
![[Pasted image 20220603033743.png]]


### Смещение и разброс
![[Pasted image 20220603033850.png]]


### Переобучение
![[Pasted image 20220603034148.png]]


### Переобучение - кросс валидация 
Когда разбиваем выборку на K блоков 
и один блок используем как тестовый а остальные для обучения, и потихоньку меняем их.
![[Pasted image 20220603034431.png]]

### Гиперпараметры
![[Pasted image 20220603034659.png]]









