#  Как работает фильтр Калмана в картинках

Фильтр Калмана это такой мощный инструмент для объединения информации в условиях неопределённости.

Можно использовать фильтр Калмана в любом месте, где у вас есть "Неточная информация" о какой-то динамической системе и мы можем сделать "обоснованное предположение" о том что эта система будет делать дальше (у нас есть математическая модель этой системы). Даже если какие то неожиданные события вмешаются в нашу модель фильтр Калмана довольно часто может воспользоваться корреляцией между разными измеряемыми элементами и отработает как надо.

Фильтры Калмана идеально подходят для систем, которые непрерывно меняются. Их преимущество в том, что они не требуют большого количества памяти (нужно хранить только предыдущий отсчет)  и они очень быстро работают. Это делает их отличным вариантом в reak-time и embedded системах.

В основном в объяснениях из гугла куча сложной математики, а тут вроде как более ясное объяснение, хотя тоже надо знать основы тервера и линала. 

## Что мы можем сделать с фильтром Калмана 
(Небольшой пояснителтный пример)
Мы строим маленького робота, который может ходить по лесу и для навигации он точно должен знать, где именно он находится.
![[Pasted image 20220701143044.png]]

Мы скажем, что наш робот имеет состояние $\large \bar{x_{k}}$ которое включает в себя координату(p) и скорость(v):
$$\large
\bar{x_{k}} = (\bar{p}, \bar{v})
$$
Обратим внимание, что состояние - это просто список чисел описывающий базовую конфигурацию нашей системы. Это может быть что угодно. В нашем примере это просто координата и скорость, но можно еще добавить количество бензина в баке, температуру двигателя положение пальца на тачпаде у пользователя и вообще что угодно что нам отслеживать.

Так же у нашего робота есть GPS датчик, который работает с точностью +- 10 метров.  Но нам бы хотелось определять положение робота немного поточнее чем +- 10 метров, Так как в лесу много оврагов, ям, корней и деревьев и мы бы не хотели упасть, так что такого GPS нам точно не хватит.
![[Pasted image 20220701143058.png]]

Но мы можем знать еще кое что о движении нашего робота: 
Мы знаем токи которые отправляются на двигатели колес и  мы знаем, что если робот движется в одном направлении, и ничего ему не мешает двигаться дальше, то вероятно в следующий момент  времени робот так же будет двигаться в том же направлении. 
Но естественно мы не знаем все, о движении робота:
Его может подздуть ветром, колеса могут буксовать, местность может быть ухабистой, так что количество оборотов колем, так что ориентироваться на обороты колес в данном случае не корректно.

Датчик GPS сообщает нам о положении, но неточно или с некой неопределённостью и наш прогноз о движении тоже говорит нам о движении с некой неопределённостью и неточностью.

Но если мы с комбинируем эту информацию то мы получим куда более точный прогноз. И именно для этого нужен фильтр Калмана.




## Как фильтр Калмана видит нашу задачу. 
Итак наше состояние (state) так же имеет координаты (position) и скорость (velocity)
$$\large
\bar{x} = 
\begin{bmatrix}
p \\
v
\end{bmatrix}

$$
Мы не знаем фактические координаты и скорость. Может быть целый диапазон возможных скоростей и координат, но некоторые из них более вероятны чем другие
![[Pasted image 20220701163130.png]]

Фильтр Калмана предполагает  что обе переменные вектора состояний (координата и скорость в нашем случае) случайные и имеют гауссовское распределение. Каждая переменная имеет матожидание $\large \mu$ и дисперсию $\large \sigma^{2}$  

![[Pasted image 20220701164450.png]]

На графике выше видно, что скорость и координаты никак не скоррелированы, это означает, что значение одной переменной ничего не говорит о том, какое значение может иметь другая.

На графике ниже показано коррелированное распределение. В нем вероятность наблюдение конкретной координаты зависит от того, какая у нас скорость.
![[Pasted image 20220701165717.png]]

Такая ситуация может возникать, если мы оцениваем новую позицию на основе старой. Если наша скорость была высокой, то мы вероятно подвинулись дальше, поэтому значение наших координат станет больше. А если мы двигаемся медленно, то и координаты меняются не так существенно.

Такие корреляции важно отслеживать, потому что это дает нам больше информации: один элемент измерения говорит нам что то о том каким может быть другой элемент. 
И это цель фильтра Калмана, мы хотим выжать максимум информации из наших неточных измерений как можно больше.

Эти корреляции описываются так называемой ковариационной матрицей. Каждый элемент матрицы $\large Σ_{ij}$ это степень корреляции между i-тым и j-тым элементом измерения. (эта матрица симметричная, поэтому не имеет значение поменяем ли мы местами i и j) 
Ковариационная матрица  часто обозначается значком $\large \Sigma$ поэтому мы и называли её элементы  $\large Σ_{ij}$.
![[Pasted image 20220701194425.png]]




## Матричное описание нашей задачи 
Мы моделируем наше знание о состоянии(state) как гауссовское распределение. Поэтому в момент времени **k** нам нужны 2 части информации:  
* Мы назовем нашу лучшую оценку $\large \hat{x}_{k}$ (это наши матожидания $\large \mu$)
*  Их ковариционную матрицу $\large \mathbf{P}_{k}$ 

$$\large
\hat{x}_{k} = 
\begin{bmatrix}
position \\
velocity
\end{bmatrix}
$$
$$\large
\mathbf{P}_{k} = 
\begin{bmatrix}
 \Sigma_{pp}&\Sigma_{pv}  \\
\Sigma_{vp} & \Sigma_{vv} \\
\end{bmatrix}
$$
Конечно в данном случае мы используем только координаты и скорость,  но полезно держать в голове, что состояние(state) может содержать любое количество переменных и представлять из себя все, что мы захотим.

Теперь нам нужен какой-то способ посмотреть на **текущее состояние** (в момент времени **k-1**) и как-то **предсказать следующее состояние** в момент времени **k**.

Помним, что мы не знаем точно какое у нас "реальное" состояние(state), но для нашей функции предсказаний это не важно, она просто работает для всех элементов и просто дает нам новое распределение:
![[Pasted image 20220701200316.png]]

Мы можем представить этот шаг прогнозирования с помощью матрицы $\large \mathbf{F}_{k}$ :
![[Pasted image 20220701200436.png]]

Эта функция берёт *каждую точку* в нашей оригинальной оценке и перемещает их в новое предсказанное место, куда наша система переместилась бы, если бы первоначальная оценка была бы правильной.

Давайте воспользуемся всем этим добром. Как бы мы использовали матрицу для предсказания координат и скорости в следующий момент в будущем? Воспользуемся простой формулой из начальной школы:
$$\large
{\color{Red} p_{k}} = {\color{Cyan} p_{k-1}}+ \Delta t{\color{Cyan} v_{k-1}} 
$$
$$\large
{\color{Red} v_{k}} = \qquad \qquad {\color{Cyan} v_{k-1}} 
$$

И то же самое в матричном представлении:
$$\large
{\color{Red} \hat{x}_{k}} = 
\begin{bmatrix}
 1 & \Delta t \\
 0 & 1 \\
\end{bmatrix}
{\color{Cyan} \hat{x}_{k-1}} =
\mathbf{F}_{k}{\color{Cyan} \hat{x}_{k-1}}
$$
Итак, мы получили **матрицу предсказаний** которая дает нам наше следующее состояние(state) но мы все еще не знаем как нам обновлять нашу матрицу ковариаций. 

Для этого нам нужна другая формула. Если мы умножим каждую точку в распределении на матрицу $\large \mathbf{A}$, то что тогда происходит с матрицей ковариаций $\large \Sigma$ ?

Из математики (и прочих умных штук) имеем такую структуру:
$$\large
Cov(x) = \Sigma
$$
$$\large
Cov({\color{Red} \mathbf{A}}x) = {\color{Red} \mathbf{A}}\Sigma{\color{Red} \mathbf{A}}^T
$$
И в применении к нашему примеру:
$$\large
{\color{Red} \hat{x}_{k}}  =
\mathbf{F}_{k}{\color{Cyan} \hat{x}_{k-1}}
$$
$$\large
{\color{Red} \mathbf{P}_{k}}  =
\mathbf{F}_{k}{\color{Cyan} \mathbf{P}_{k-1}}
\mathbf{F}^{T}_{k}
$$

## Внешнее влияние
Мы не все учли, на систему могут оказываться внешние воздействия, а мы их не учитываем.

Например, если состояние(state) модели - это движение поезда, машинист может нажать на газ, что заставит поезд ускорится. Аналогично в нашем примере с роботом: мозги робота могут дать команду колесам крутится или же остановиться. И если мы будем знать эту дополнительную информацию о том что происходит, мы можем поместить её в вектор $\large \bar{u}_{k}$  кое что с ним сделать и добавить в наше предсказание как коррекцию.

Допустим мы знаем наше ожидаемое ускорение **a** которое мы высчитываем исходи из информации о том на сколько мы открыли дроссельную заслонку в движке, или какие токи подали на моторы.
Из школьной программы базовой кинематики получаем вот такие формулы:

$$\large
{\color{Red} p_{k}} = {\color{Cyan} p_{k-1}}+ \Delta t{\color{Cyan} v_{k-1}} +
\frac{1}{2} {\color{orange} a}\Delta t^2
$$
$$\large
{\color{Red} v_{k}} = \qquad \qquad {\color{Cyan} v_{k-1}} + {\color{orange} a}\Delta t^2
$$
Или то же в матричном представлении: 
$$\large
{\color{Red} \hat{x}_{k}}  =
\mathbf{F}_{k}{\color{Cyan} \hat{x}_{k-1}} +
\begin{bmatrix}
\frac{\Delta t^2}{2} \\
\Delta t
\end{bmatrix}
 {\color{orange} a}
$$
$$\large
  =
\mathbf{F}_{k}{\color{Cyan} \hat{x}_{k-1}} +
\mathbf{B}_{k}
 {\color{orange} \bar{u}_{k}}
$$
$\large \mathbf{B}_{k}$ - матрица управления.
$\large {\color{orange} \bar{u}_{k}}$ - вектор управления.
(для самых простых систем без внешнего управления, их можно опустить)

Добавим еще одну детальку. Что случится если наше предсказание не будет 100% соответствовать тому что происходит на самом деле?

## Внешняя неопределённость

У нас всё хорошо, если состояние(state)  эволюционирует основываясь на своих свойствах. Так же нас устраивает если состояние(state) эволюционирует от внешних воздействий, которые мы знаем(вектором управления)

А как на счет тех сил которые мы не учитываем? Например если мы трекаем квадрокоптер, его может сдувать ветер. Если наш робот колесный, то колеса могут буксовать, или он может тормозить на неровностях. Мы не можем отслеживать эти вещи и если что то из этого произойдёт, то мы ошибёмся в прогнозах, потому что не учли это.

Мы можем моделировать эту неопределённость связанную с внешними воздействиями. (теми которые от нас не зависят) добавляя на каждом новом шаге прогнозирования дополнительную неопределённость.
![[Pasted image 20220703031709.png]]

Каждое состояние(state) на нашем предыдущем шаге может переходить в целый ряд состояний на следующем шаге. Поскольку нам ОООчень нравится гауссовские распределения, мы говорим, что каждая точка из $\large {\color{Cyan} \hat{x}_{k-1}}$ перемещается  куда то в гауссовское распределение с коварицией $\large {\color{Green} \mathbf{Q}_{k}}$. Другими словами, мы рассматриваем такие не отслеживаемые воздействия, как **шум** с ковариацией $\large {\color{Green} \mathbf{Q}_{k}}$.
![[Pasted image 20220703035906.png]]

Это все нам создает новое финальное гауссовское распределение с другой ковариацией (но с тем же матожиданием) 

![[Pasted image 20220703040045.png]]

Мы получаем расширенную ковариацию просто добавляя $\large {\color{Green} \mathbf{Q}_{k}}$, 
 Получаем вот такое расширенное выражение для шага предсказаний:
$$\large
{\color{Red} \hat{x}_{k}}  =
\mathbf{F}_{k}{\color{Cyan} \hat{x}_{k-1}} +
\mathbf{B}_{k}
 {\color{orange} \bar{u}_{k}}
$$
$$\large
{\color{Red} \mathbf{P}_{k}}  =
\mathbf{F}_{k}{\color{Cyan} \mathbf{P}_{k-1}}
\mathbf{F}^{T}_{k} + {\color{Green} \mathbf{Q}_{k}}
$$
Другими словами, **новое лучшее предсказание** это **предсказание**, сделанное  из **предыдущего лучшего предсказания** плюс поправка из **известного управляющего воздействия**
И **новая неопределённость** прогнозируется на основе **неопределённости с предыдущего  шага** с добавлением **дополнительной неопределённости из окружающей среды**

Хорошо, у нас теперь есть нечеткая оценка того, где наша система может быть, получаемая из $\large {\color{Red} \hat{x}_{k}}$ и $\large {\color{Red} \mathbf{P}_{k}}$. Что происходит когда мы получаем данные с наших датчиков?



## Уточнение оценки с помощью измерений

У нас может быть несколько датчиков, которые дают нам информацию о нашей системе. Пока не сильно имеет значение что они измеряют. Возможно один из них гироскоп, считывает положение, а другой - спидометр считывает скорость. Каждый датчик сообщаяет нам что то **косвенное** о состоянии(state)

![[Pasted image 20220703050521.png]]

Обратим внимание, что единицы измерений и масштаб данных с датчиков может не быть таким же как и у состояния(state) которое мы отслеживаем. Можем догадаться к чему это нас приведет: Мы будем моделировать сенсоры с помощью матрицы $\large \mathbf{H}_{k}$. 

![[Pasted image 20220703051110.png]]

Мы можем вычислить ожидаемое распределение показаний с датчиков которое мы ожидаем увидеть уже привычным способом:
$$\large
\bar{\mu}_{expected} = \mathbf{H}_{k}{\color{Red} \hat{x}_{k}}
$$
$$\large
\Sigma_{expected} = \mathbf{H}_{k}{\color{Red} \mathbf{P}_{k}}\mathbf{H}_{k}^{T}
$$

Одна штука, в которой фильтры Калманы работают превосходно - это борьба с шумами датчиков.  Другими словами наши сенсоры работают с погрешностью,  и каждое состояние(state) в нашем оригинальном приближении может соотносится с целым рядом показаний с датчика.

![[Pasted image 20220703052350.png]]

С каждого чтения данных мы можем "угадывать" что наша системы была в конкретном состоянии(state). Но поскольку у нас и тут есть неопределённость, **некоторые состояния(state) более вероятны чем другие** получены из наших считаных данных.

![[Pasted image 20220703053555.png]]

Мы назовем **ковариацию** этой неопределённости (т.е  шумов датчика) $\large {\color{Green} \mathbf{R}_{k}}$.  Распределение имеет мат.ожидание  которое равно тому что мы считали с датчика, и мы назовем его $\large {\color{LimeGreen} \bar{\mathbf{z}}_{k}}$

Итак, теперь у нас есть два гауссовских распределения: 
Одно из преобразований нашей математической модели, а другое распределение вокруг показаний считанных с датчиков.

![[Pasted image 20220703054529.png]]

Нам надо как то попытаться скомбинировать наши догадки полученные на основе предсказаний модели (состояние(state)) которые на рисунке розовые и другими догадками которые базируются на чтении датчиков(зелёные) которые мы и считали.

И так, какое у нас теперь наше новое наиболее вероятное состояние(state)? Для любых возможных считаных показаний $\large (z_{1}, z_{2})$  у нас есть две объединенные вероятности:
1. (Зеленое) Вероятность того, что наше считывание данных датчиков $\large {\color{LimeGreen} \bar{\mathbf{z}}_{k}}$ - это неверное измерение $\large (z_{1}, z_{2})$ 
2. (розовое)  вероятность того, что наша предыдущая оценка считает что $\large (z_{1}, z_{2})$ это то значение которое мы должны считать.

И так у нас есть 2 вероятности, мы хотим что бы обе были верны, тогда просто их перемножим.
![[Pasted image 20220703155550.png]]

И так у нас осталось **перекрытие**(overlap)  область где обе вероятности - вероятны. И это область куда точнее чем наши предыдущие оценки. Мат.ожидание этого нового распределения это наилучшее предположение о нашем положении изходя из всей имеющийся у нас информации. 

![[Pasted image 20220703155938.png]]

Оказывается при перемножении двух гауссиан со своими средними и дисперсиями у нас получается у нас получится новая гауссиана со своим новым мат.ожиданием и своей новой дисперсией. И конечно у нас должна быть формула для таких расчетов. 


## Комбинирование гауссиан

Давайте найдем эту формулу! 
Сначала рассмотрим одномерный случай.  Одномерная гауссиана с дисперсией $\large \sigma^{2}$ и мат.ожиданием $\large \mu$ определяется так:
$$\large
\cal{N}(x, \mu,\sigma) = 
\frac{1}{\sigma \sqrt{2\pi}}
e^{-\frac{(x-\mu)^{2}}{2\sigma^2}}

$$
Мы хотим знать, что происходит, когда мы перемножаем 2 гауссовские кривые вместе. Синяя кривая ниже - это ненормированное пересечение двух других гауссиан:

![[Pasted image 20220703161945.png]]

$$\large
\cal{N}(x,\mu_{0},\sigma_{0})\cdot \cal{N}(x,\mu_{1},\sigma_{1})
\overset{?}{=}
\cal{N}(x,\mu',\sigma')

$$
Просто подставив одно в другое, посчитав и отнормировав до единицы получаем:

$$\large 
\mu'=\mu_{0}+
\frac{\sigma_{0}^{2}(\mu_{1}-\mu_{0})}
{\sigma_{0}^{2}+\sigma_{1}^{2}}
$$
$$\large 
\sigma'^{2}=\sigma_{0}^{2}-
\frac{\sigma_{0}^{4}}
{\sigma_{0}^{2}+\sigma_{1}^{2}}
$$
Или немного упростив заменив часть формул на $\large {\color{Purple} \mathbf{k}}$ 
$$\large
{\color{Purple} \mathbf{k}} =
\frac{\sigma^{2}_{0}}{\sigma^{2}_{0}+\sigma^{2}_{1}}
$$
$$\large 
\mu'=\mu_{0}+
{\color{Purple} \mathbf{k}}(\mu_{1}-\mu_{0})
$$
$$\large 
\sigma'^{2}=\sigma_{0}^{2}- 
{\color{Purple} \mathbf{k}}\sigma_{0}^{2}
$$

Получается все довольно просто.

И то же в матричной форме. перепишем три предыдущих уравнение в матричной форме. Если $\large \Sigma$ - ковариационная матрица гауссовского распределения и $\large \bar{\mu}$ - вектор мат.ожиданий вдоль каждой оси, тогда:
$$\large
{\color{Purple} \mathbf{K}} =
\Sigma_{0}(\Sigma_{0}+\Sigma_{1})^{-1}
$$
$$\large 
\bar{\mu}'=\bar{\mu}_{0}+
{\color{Purple} \mathbf{K}}(\bar{\mu}_{1}-\bar{\mu}_{0})
$$
$$\large 
\Sigma'=\Sigma_{0}- 
{\color{Purple} \mathbf{K}}\Sigma_{0}
$$

$\large {\color{Purple} \mathbf{K}}$ это матрица которая называется **Kalman gain** и мы её сейчас будем использовать.


## Собираем все вместе

У на есть 2 распределения: 
Предсказанное моделью распределение $\large ({\color{Purple} \mathbf{\mu_{0}}}, {\color{Red} \mathbf{\Sigma_{0}}}) = ({\color{Purple} \mathbf{H}_{k}}{\color{Purple} \hat{x}_{k}},{\color{Red} \mathbf{H}_{k}} {\color{Red} \mathbf{P}_{k}}{\color{Red} \mathbf{H}_{k}^{T}})$    Наблюдаемые измерения$\large ({\color{LimeGreen} \mathbf{\mu_{1}}}, {\color{SeaGreen} \mathbf{\Sigma_{1}}}) = ({\color{LimeGreen} \bar{z}_{k}}, {\color{SeaGreen} \mathbf{R_{k}}})$         

Подставляем их в уравнения из предыдущего пункта и получаем:
![[Pasted image 20220703180921.png]]
![[Pasted image 20220703180949.png]]

Мы можем сократить одну $\large \mathbf{H}_{k}$ во всех этих уравнениях заметим что одна спрятана в $\large \mathbf{K}$. Так же во 2ом уравнении можем сократить $\large \mathbf{H}_{k}^{T}$. Тогда получаем такие финальные уравнения для каждого шага уравнения:
![[Pasted image 20220704024756.png]]

Вот и всё! $\large {\color{Cyan} \hat{x}'_{k}}$ наш новый вектор лучшего предсказания и мы можем проталкивать его по схеме нарисованной ниже вместе с матрицей P как на рисунке ниже

![[Pasted image 20220704025236.png]]

## Подведение итогов 
Такие фильтра Калмана работают с  замоделироваными линейными системами. Для нелинейных систем используються **extended Kalman filter** (EKF) они работатют за счет линеаризации предсказаний и измерений относительно их матожидания. 



Kalman Filter hyperparameters:
F - state transition matrix.
H - measurement matrix.
P - initial state uncertainty covariance matrix 
Q - model noise covariance (model uncertainty).
R - measurement noise covariance (measurement  uncertainty).

















































































